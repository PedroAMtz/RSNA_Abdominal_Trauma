{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Experiment on Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from keras import backend as K\n",
    "from glob import glob\n",
    "import pydicom\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Conv3D, MaxPool3D, Flatten, Dense\n",
    "from keras.layers import Dropout, Input, BatchNormalization\n",
    "import cv2\n",
    "from scipy.ndimage import zoom\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_3d_volumes(data, path, number_idx):\n",
    "    \n",
    "    data_to_merge = data[[\"patient_id\", \"any_injury\"]]\n",
    "    shuffled_data = data_to_merge.sample(frac=1, random_state=42)\n",
    "    shuffled_indexes = shuffled_data.index[:number_idx]\n",
    "    selected_rows = shuffled_data.loc[shuffled_indexes]\n",
    "    data_to_merge_processed = selected_rows.reset_index()\n",
    "    \n",
    "    total_paths = []\n",
    "    patient_ids = []\n",
    "    category = []\n",
    "    \n",
    "    for patient_id in range(len(data_to_merge_processed)):\n",
    "    \n",
    "        p_id = str(data_to_merge_processed[\"patient_id\"][patient_id])\n",
    "        str_imgs_path = path + p_id + '/'\n",
    "        patient_img_paths = []\n",
    "\n",
    "        for file in glob(str_imgs_path + '*'):\n",
    "            for image_path in glob(file + '/*'):\n",
    "                 patient_img_paths.append(image_path)\n",
    "    \n",
    "        total_paths.append(patient_img_paths)\n",
    "        patient_ids.append(data_to_merge_processed[\"patient_id\"][patient_id])\n",
    "        category.append(data_to_merge_processed[\"any_injury\"][patient_id])\n",
    "    \n",
    "    final_data = pd.DataFrame(list(zip(patient_ids, total_paths, category)),\n",
    "               columns =[\"Patient_id\", \"Patient_paths\", \"Patient_category\"])\n",
    "    \n",
    "    return final_data \n",
    "\n",
    "def training_plot(metrics, history):\n",
    "    f, ax = plt.subplots(1, len(metrics), figsize=(5*len(metrics), 4))\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        ax[idx].plot(history.history[metric], ls='dashed')\n",
    "        ax[idx].set_xlabel(\"Epochs\")\n",
    "        ax[idx].set_ylabel(metric)\n",
    "        ax[idx].plot(history.history['val_' + metric]);\n",
    "        ax[idx].legend([metric, 'val_' + metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image3DGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, target_depth=64, target_size=(128,128)):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.target_depth = target_depth\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "    \n",
    "    def resize_img(self, img_paths):\n",
    "        preprocessed_images = []\n",
    "        for image_path in img_paths: \n",
    "            image = pydicom.read_file(image_path)\n",
    "            image = image.pixel_array\n",
    "            image = cv2.resize(image, self.target_size)\n",
    "            image_array = np.array(image)\n",
    "            preprocessed_images.append(image_array)\n",
    "\n",
    "    # Create an empty volume array\n",
    "        volume_shape = (self.target_size[0], self.target_size[1], len(preprocessed_images)) \n",
    "        volume = np.zeros(volume_shape, dtype=np.uint16)\n",
    "    # Populate the volume with images\n",
    "        for i, image_array in enumerate(preprocessed_images):\n",
    "            volume[:,:,i] = image_array\n",
    "        return volume\n",
    "    \n",
    "    def change_depth_siz(self, patient_volume):\n",
    "        desired_depth = self.target_depth\n",
    "        current_depth = patient_volume.shape[-1]\n",
    "        depth = current_depth / desired_depth\n",
    "        depth_factor = 1 / depth\n",
    "        img_new = zoom(patient_volume, (1, 1, depth_factor), mode='nearest')\n",
    "        return img_new\n",
    "    \n",
    "    def normalize_volume(self, resized_volume):\n",
    "        original_shape = resized_volume.shape\n",
    "        flattened_image = resized_volume.reshape((-1,))\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "        normalized_flattened_image = scaler.fit_transform(flattened_image.reshape((-1, 1)))\n",
    "        normalized_volume_image = normalized_flattened_image.reshape(original_shape)\n",
    "        return normalized_volume_image\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        resized_images = []\n",
    "        for list_files in batch_x:\n",
    "            preprocessed_images = self.resize_img(list_files)\n",
    "            resized_images_siz = self.change_depth_siz(preprocessed_images)\n",
    "            normalized_volume = self.normalize_volume(resized_images_siz)\n",
    "            resized_images.append(normalized_volume)\n",
    "\n",
    "        resized_images = np.array(resized_images)\n",
    "        return resized_images, np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block_3d(inputs, num_filters):\n",
    "\n",
    "    x = Conv3D(filters=num_filters, kernel_size=(3,3,3),\n",
    "    activation=\"relu\")(inputs)\n",
    "    x = MaxPool3D(pool_size=(2,2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "# function to define the dense block of the network, composed by:\n",
    "# 2 dense layer with 2 dropout layes in between and one output layer for clasification\n",
    "def dense_block(flatten_layer):\n",
    "    dense_layer_1 = Dense(units=512, activation='relu')(flatten_layer)\n",
    "    dense_layer_1 = Dropout(0.4)(dense_layer_1)\n",
    "\n",
    "    #dense_layer_2 = Dense(units=256, activation='relu')(dense_layer_1)\n",
    "    #dense_layer_2 = Dropout(0.4)(dense_layer_2)\n",
    "    output_layer = Dense(units=2, activation='softmax')(dense_layer_1)\n",
    "\n",
    "    return output_layer\n",
    "\n",
    "# Main function to build the 3D Conv Network\n",
    "def build_3d_network(input_shape):\n",
    "\n",
    "    input_layer = Input(input_shape)\n",
    "\n",
    "    x1 = convolutional_block_3d(input_layer, 64)\n",
    "    x2 = convolutional_block_3d(x1, 64)\n",
    "    x3 = convolutional_block_3d(x2, 128)\n",
    "    x4 = convolutional_block_3d(x3, 256)\n",
    "\n",
    "    flatten_layer = Flatten()(x4)\n",
    "\n",
    "    output = dense_block(flatten_layer)\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "    model.compile(loss='mae',optimizer=SGD(learning_rate=1e-06, momentum=0.99, decay=0.0, nesterov=False), metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'Experiments_ckpt/experiment_{}_checkpoint.ckpt'.format(str(run_id))\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                                    save_weights_only=True,\n",
    "                                                                    monitor='val_accuracy',\n",
    "                                                                    mode='max',\n",
    "                                                                    save_best_only=True)\n",
    "\n",
    "train_data = pd.read_csv(f\"D:/Downloads/rsna-2023-abdominal-trauma-detection/train.csv\")\n",
    "path = 'D:/Downloads/rsna-2023-abdominal-trauma-detection/train_images/'\n",
    "paths = get_data_for_3d_volumes(train_data, path=path, number_idx=2000)\n",
    "    \n",
    "train_data_gen = Image3DGenerator(paths[\"Patient_paths\"][:1600], paths[\"Patient_category\"][:1600], batch_size=4)\n",
    "valid_data_gen = Image3DGenerator(paths[\"Patient_paths\"][1600:], paths[\"Patient_category\"][1600:], batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (128, 128, 64, 1)\n",
    "model = build_3d_network(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data_gen, epochs=1000, validation_data=valid_data_gen, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_plot(['loss', 'acc'], history)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
