{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Experiment on Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from keras import backend as K\n",
    "from glob import glob\n",
    "import pydicom\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Conv3D, MaxPool3D, Flatten, Dense\n",
    "from keras.layers import Dropout, Input, BatchNormalization\n",
    "import cv2\n",
    "from scipy.ndimage import zoom\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_3d_volumes(data, path, number_idx):\n",
    "    \n",
    "    data_to_merge = data[[\"patient_id\", \"any_injury\"]]\n",
    "    shuffled_data = data_to_merge.sample(frac=1, random_state=42)\n",
    "    shuffled_indexes = shuffled_data.index[:number_idx]\n",
    "    selected_rows = shuffled_data.loc[shuffled_indexes]\n",
    "    data_to_merge_processed = selected_rows.reset_index()\n",
    "    \n",
    "    total_paths = []\n",
    "    patient_ids = []\n",
    "    category = []\n",
    "    \n",
    "    for patient_id in range(len(data_to_merge_processed)):\n",
    "    \n",
    "        p_id = str(data_to_merge_processed[\"patient_id\"][patient_id])\n",
    "        str_imgs_path = path + p_id + '/'\n",
    "        patient_img_paths = []\n",
    "\n",
    "        for file in glob(str_imgs_path + '*'):\n",
    "            for image_path in glob(file + '/*'):\n",
    "                 patient_img_paths.append(image_path)\n",
    "    \n",
    "        total_paths.append(patient_img_paths)\n",
    "        patient_ids.append(data_to_merge_processed[\"patient_id\"][patient_id])\n",
    "        category.append(data_to_merge_processed[\"any_injury\"][patient_id])\n",
    "    \n",
    "    final_data = pd.DataFrame(list(zip(patient_ids, total_paths, category)),\n",
    "               columns =[\"Patient_id\", \"Patient_paths\", \"Patient_category\"])\n",
    "    \n",
    "    return final_data \n",
    "\n",
    "def training_plot(metrics, history):\n",
    "    f, ax = plt.subplots(1, len(metrics), figsize=(5*len(metrics), 4))\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        ax[idx].plot(history.history[metric], ls='dashed')\n",
    "        ax[idx].set_xlabel(\"Epochs\")\n",
    "        ax[idx].set_ylabel(metric)\n",
    "        ax[idx].plot(history.history['val_' + metric]);\n",
    "        ax[idx].legend([metric, 'val_' + metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image3DGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, target_depth=64, target_size=(128,128)):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.target_depth = target_depth\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "    \n",
    "    def resize_img(self, img_paths):\n",
    "        preprocessed_images = []\n",
    "        for image_path in img_paths: \n",
    "            image = pydicom.read_file(image_path)\n",
    "            image = image.pixel_array\n",
    "            image = cv2.resize(image, self.target_size)\n",
    "            image_array = np.array(image)\n",
    "            preprocessed_images.append(image_array)\n",
    "\n",
    "    # Create an empty volume array\n",
    "        volume_shape = (self.target_size[0], self.target_size[1], len(preprocessed_images)) \n",
    "        volume = np.zeros(volume_shape, dtype=np.uint16)\n",
    "    # Populate the volume with images\n",
    "        for i, image_array in enumerate(preprocessed_images):\n",
    "            volume[:,:,i] = image_array\n",
    "        return volume\n",
    "    \n",
    "    def change_depth_siz(self, patient_volume):\n",
    "        desired_depth = self.target_depth\n",
    "        current_depth = patient_volume.shape[-1]\n",
    "        depth = current_depth / desired_depth\n",
    "        depth_factor = 1 / depth\n",
    "        img_new = zoom(patient_volume, (1, 1, depth_factor), mode='nearest')\n",
    "        return img_new\n",
    "    \n",
    "    def normalize_volume(self, resized_volume):\n",
    "        original_shape = resized_volume.shape\n",
    "        flattened_image = resized_volume.reshape((-1,))\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "        normalized_flattened_image = scaler.fit_transform(flattened_image.reshape((-1, 1)))\n",
    "        normalized_volume_image = normalized_flattened_image.reshape(original_shape)\n",
    "        return normalized_volume_image\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        resized_images = []\n",
    "        for list_files in batch_x:\n",
    "            preprocessed_images = self.resize_img(list_files)\n",
    "            resized_images_siz = self.change_depth_siz(preprocessed_images)\n",
    "            normalized_volume = self.normalize_volume(resized_images_siz)\n",
    "            resized_images.append(normalized_volume)\n",
    "\n",
    "        resized_images = np.array(resized_images)\n",
    "        return resized_images, np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block_3d(inputs, num_filters):\n",
    "\n",
    "    x = Conv3D(filters=num_filters, kernel_size=(3,3,3),\n",
    "    activation=\"relu\")(inputs)\n",
    "    x = MaxPool3D(pool_size=(2,2,2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "# function to define the dense block of the network, composed by:\n",
    "# 2 dense layer with 2 dropout layes in between and one output layer for clasification\n",
    "def dense_block(flatten_layer):\n",
    "    dense_layer_1 = Dense(units=512, activation='relu')(flatten_layer)\n",
    "    dense_layer_1 = Dropout(0.4)(dense_layer_1)\n",
    "\n",
    "    #dense_layer_2 = Dense(units=256, activation='relu')(dense_layer_1)\n",
    "    #dense_layer_2 = Dropout(0.4)(dense_layer_2)\n",
    "    output_layer = Dense(units=2, activation='softmax')(dense_layer_1)\n",
    "\n",
    "    return output_layer\n",
    "\n",
    "# Main function to build the 3D Conv Network\n",
    "def build_3d_network(input_shape):\n",
    "\n",
    "    input_layer = Input(input_shape)\n",
    "\n",
    "    x1 = convolutional_block_3d(input_layer, 64)\n",
    "    x2 = convolutional_block_3d(x1, 64)\n",
    "    x3 = convolutional_block_3d(x2, 128)\n",
    "    x4 = convolutional_block_3d(x3, 256)\n",
    "\n",
    "    flatten_layer = Flatten()(x4)\n",
    "\n",
    "    output = dense_block(flatten_layer)\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "    model.compile(loss='mae',optimizer=SGD(learning_rate=1e-06, momentum=0.99, decay=0.0, nesterov=False), metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'Experiments_ckpt/experiment__checkpoint.ckpt'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                                    save_weights_only=True,\n",
    "                                                                    monitor='val_accuracy',\n",
    "                                                                    mode='max',\n",
    "                                                                    save_best_only=True)\n",
    "\n",
    "train_data = pd.read_csv(f\"D:/Downloads/rsna-2023-abdominal-trauma-detection/train.csv\")\n",
    "path = 'D:/Downloads/rsna-2023-abdominal-trauma-detection/train_images/'\n",
    "paths = get_data_for_3d_volumes(train_data, path=path, number_idx=2000)\n",
    "    \n",
    "train_data_gen = Image3DGenerator(paths[\"Patient_paths\"][:1600], paths[\"Patient_category\"][:1600], batch_size=4)\n",
    "valid_data_gen = Image3DGenerator(paths[\"Patient_paths\"][1600:], paths[\"Patient_category\"][1600:], batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 64, 1)  0         \n",
      "                             ]                                   \n",
      "                                                                 \n",
      " conv3d (Conv3D)             (None, 126, 126, 62, 64)  1792      \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 63, 63, 31, 64)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 63, 63, 31, 64)   256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 61, 61, 29, 64)    110656    \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 30, 30, 14, 64)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 30, 30, 14, 64)   256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 28, 28, 12, 128)   221312    \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 14, 14, 6, 128)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 14, 14, 6, 128)   512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3d_3 (Conv3D)           (None, 12, 12, 4, 256)    884992    \n",
      "                                                                 \n",
      " max_pooling3d_3 (MaxPooling  (None, 6, 6, 2, 256)     0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 6, 6, 2, 256)     1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               9437696   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,659,522\n",
      "Trainable params: 10,658,498\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (128, 128, 64, 1)\n",
    "model = build_3d_network(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_data_gen, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mvalid_data_gen, callbacks\u001b[39m=\u001b[39;49m[model_checkpoint_callback])\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:980\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    976\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    978\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    979\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 980\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    981\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m   _, _, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[0;32m    983\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    984\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data_gen, epochs=100, validation_data=valid_data_gen, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_plot(['loss', 'acc'], history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
