{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-14T01:46:20.683965Z","iopub.status.busy":"2023-09-14T01:46:20.683600Z","iopub.status.idle":"2023-09-14T01:46:30.227068Z","shell.execute_reply":"2023-09-14T01:46:30.226077Z","shell.execute_reply.started":"2023-09-14T01:46:20.683928Z"},"trusted":true},"outputs":[],"source":["import wandb\n","import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Input, Flatten, LSTM, Dense, Reshape, Dropout\n","from tensorflow.keras.models import Model\n","\n","from types import SimpleNamespace\n","import keras\n","import numpy as np\n","import pandas as pd\n","import pydicom\n","import cv2\n","from scipy.ndimage import zoom\n","from sklearn import preprocessing\n","from glob import glob\n","import re\n","import sqlite3\n","\n","import matplotlib.pyplot as plt\n","import os \n","import nibabel as nib\n","from glob import glob\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical\n","from keras import backend as K\n","tf.config.run_functions_eagerly(True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-14T01:46:30.231118Z","iopub.status.busy":"2023-09-14T01:46:30.229868Z","iopub.status.idle":"2023-09-14T01:47:24.260316Z","shell.execute_reply":"2023-09-14T01:47:24.259365Z","shell.execute_reply.started":"2023-09-14T01:46:30.231082Z"},"trusted":true},"outputs":[],"source":["wandb.login(anonymous=\"allow\")"]},{"cell_type":"markdown","metadata":{},"source":["****DATA PREPROCESSING****"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-14T01:47:24.262839Z","iopub.status.busy":"2023-09-14T01:47:24.262044Z","iopub.status.idle":"2023-09-14T01:47:24.279515Z","shell.execute_reply":"2023-09-14T01:47:24.278527Z","shell.execute_reply.started":"2023-09-14T01:47:24.262801Z"},"trusted":true},"outputs":[],"source":["def window_converter(image, window_width=400, window_level=50):      \n","    img_min = window_level - window_width // 2\n","    img_max = window_level + window_width // 2\n","    window_image = image.copy()\n","    window_image[window_image < img_min] = img_min\n","    window_image[window_image > img_max] = img_max\n","    #image = (image / image.max() * 255).astype(np.float64)\n","    return window_image\n","\n","def transform_to_hu(medical_image, image):\n","    meta_image = pydicom.dcmread(medical_image)\n","    intercept = meta_image.RescaleIntercept\n","    slope = meta_image.RescaleSlope\n","    hu_image = image * slope + intercept\n","    return hu_image\n","\n","def standardize_pixel_array(dcm: pydicom.dataset.FileDataset) -> np.ndarray:\n","    # Correct DICOM pixel_array if PixelRepresentation == 1.\n","        pixel_array = dcm.pixel_array\n","        if dcm.PixelRepresentation == 1:\n","            bit_shift = dcm.BitsAllocated - dcm.BitsStored\n","            dtype = pixel_array.dtype \n","            pixel_array = (pixel_array << bit_shift).astype(dtype) >> bit_shift\n","        return pixel_array\n","    \n","def resize_img(img_paths, target_size=(128, 128)):\n","        volume_shape = (target_size[0], target_size[1], len(img_paths)) \n","        volume = np.zeros(volume_shape, dtype=np.float64)\n","        for i, image_path in enumerate(img_paths):\n","            image = pydicom.read_file(image_path)\n","            image = standardize_pixel_array(image)\n","            hu_image = transform_to_hu(image_path, image)\n","            window_image = window_converter(hu_image)\n","            image = cv2.resize(window_image, target_size)\n","            volume[:,:,i] = image\n","        return volume\n","    \n","def normalize_volume(resized_volume):\n","    original_shape = resized_volume.shape\n","    flattened_image = resized_volume.reshape((-1,))\n","    scaler = preprocessing.MinMaxScaler()\n","    normalized_flattened_image = scaler.fit_transform(flattened_image.reshape((-1, 1)))\n","    normalized_volume_image = normalized_flattened_image.reshape(original_shape)\n","    return normalized_volume_image\n","\n","def generate_patient_processed_data(list_img_paths, list_labels, target_size=(128,128)):\n","\n","    height = target_size[0]\n","    width = target_size[1]\n","    depth = len(list_img_paths)\n","\n","    volume_array = np.zeros((height, width, depth), dtype=np.float64)\n","\n","    print(\"Initializing data preprocessing with the following dimensions-> Volumes:{}\".format(volume_array.shape))\n","\n","    resized_images = resize_img(list_img_paths, target_size=target_size)\n","    normalized_siz_volume = normalize_volume(resized_images)\n","    volume_array = normalized_siz_volume\n","    #volume_mask = create_3D_segmentations(list_seg_paths, target_size=target_size)\n","    labels = [list_labels for i in range(depth)]\n","    \n","    return volume_array, labels#, volume_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-14T01:47:24.282809Z","iopub.status.busy":"2023-09-14T01:47:24.282533Z","iopub.status.idle":"2023-09-14T01:47:24.295437Z","shell.execute_reply":"2023-09-14T01:47:24.294592Z","shell.execute_reply.started":"2023-09-14T01:47:24.282784Z"},"trusted":true},"outputs":[],"source":["def extract_number_from_path(path):\n","    match = re.search(r'(\\d+)\\.dcm$', path)\n","    if match:\n","        return int(match.group(1))\n","    return 0\n","\n"," \n","\n","def get_data_for_3d_volumes(data,train_data_cat, path, number_idx):\n","\n","    data_to_merge = data[[\"patient_id\", \"series_id\"]]\n","    patient_category = train_data_cat[[\"patient_id\", \"any_injury\"]]\n","\n","    merged_df = data_to_merge.merge(patient_category, on='patient_id', how='left')\n","\n","    shuffled_data = merged_df.sample(frac=1, random_state=42)\n","    shuffled_indexes = shuffled_data.index[:number_idx]\n","    selected_rows = shuffled_data.loc[shuffled_indexes]\n","    data_to_merge_processed = selected_rows.reset_index()\n","\n","    total_paths = []\n","    patient_ids = []\n","    series_ids = []\n","    category = []\n","\n","    for patient_id in range(len(data_to_merge_processed)):\n","\n","        p_id = str(data_to_merge_processed[\"patient_id\"][patient_id]) + \"/\" + str(data_to_merge_processed[\"series_id\"][patient_id])\n","        str_imgs_path = path + p_id + '/'\n","        patient_img_paths = []\n","\n"," \n","\n","        for file in glob(str_imgs_path + '/*'):\n","            patient_img_paths.append(file)\n","\n","\n","        sorted_file_paths = sorted(patient_img_paths, key=extract_number_from_path)\n","        total_paths.append(sorted_file_paths)\n","        patient_ids.append(data_to_merge_processed[\"patient_id\"][patient_id])\n","        series_ids.append(data_to_merge_processed[\"series_id\"][patient_id])\n","        category.append(data_to_merge_processed[\"any_injury\"][patient_id])\n","\n","    final_data = pd.DataFrame(list(zip(patient_ids, series_ids, total_paths, category)),\n","               columns =[\"Patient_id\",\"Series_id\", \"Patient_paths\", \"Patient_category\"])\n","\n","    return final_data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-14T01:47:24.299422Z","iopub.status.busy":"2023-09-14T01:47:24.299125Z","iopub.status.idle":"2023-09-14T01:47:24.312533Z","shell.execute_reply":"2023-09-14T01:47:24.311585Z","shell.execute_reply.started":"2023-09-14T01:47:24.299393Z"},"trusted":true},"outputs":[],"source":["def extract_number_from_path(path):\n","    match = re.search(r'(\\d+)\\.dcm$', path)\n","    if match:\n","        return int(match.group(1))\n","    return 0\n","def get_data_for_3d_volumes(data,train_data_cat, path, number_idx):\n","    \n","    data_to_merge = data[[\"patient_id\", \"series_id\"]]\n","    patient_category = train_data_cat[[\"patient_id\", \"any_injury\"]]\n","    \n","    merged_df = data_to_merge.merge(patient_category, on='patient_id', how='left')\n","    \n","    shuffled_data = merged_df.sample(frac=1, random_state=42)\n","    shuffled_indexes = shuffled_data.index[:number_idx]\n","    selected_rows = shuffled_data.loc[shuffled_indexes]\n","    data_to_merge_processed = selected_rows.reset_index()\n","    \n","    total_paths = []\n","    patient_ids = []\n","    series_ids = []\n","    category = []\n","    \n","    for patient_id in range(len(data_to_merge_processed)):\n","    \n","        p_id = str(data_to_merge_processed[\"patient_id\"][patient_id]) + \"/\" + str(data_to_merge_processed[\"series_id\"][patient_id])\n","        str_imgs_path = path + p_id + '/'\n","        patient_img_paths = []\n","\n","        for file in glob(str_imgs_path + '/*'):\n","            patient_img_paths.append(file)\n","        \n","        \n","        sorted_file_paths = sorted(patient_img_paths, key=extract_number_from_path)\n","        total_paths.append(sorted_file_paths)\n","        patient_ids.append(data_to_merge_processed[\"patient_id\"][patient_id])\n","        series_ids.append(data_to_merge_processed[\"series_id\"][patient_id])\n","        category.append(data_to_merge_processed[\"any_injury\"][patient_id])\n","    \n","    final_data = pd.DataFrame(list(zip(patient_ids, series_ids, total_paths, category)),\n","               columns =[\"Patient_id\",\"Series_id\", \"Patient_paths\", \"Patient_category\"])\n","    \n","    return final_data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-14T01:47:24.315970Z","iopub.status.busy":"2023-09-14T01:47:24.315715Z","iopub.status.idle":"2023-09-14T01:47:24.327054Z","shell.execute_reply":"2023-09-14T01:47:24.326106Z","shell.execute_reply.started":"2023-09-14T01:47:24.315946Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","buffer_size = 10\n","buffer = []\n","#\n","#def process_buffer(buffer):\n"," #   if len(buffer) >= buffer_size:\n","  #      X_batch = np.array(buffer)\n","   #     y_batch = np.array([1])\n","    #    lstm_model.train_on_batch(X_batch, y_batch)\n","     #   buffer.clear()\n","\n","#for features_sequence in features_sequences:\n","#    for feature_vector in features_sequence:\n"," #       buffer.append(feature_vector)\n","  #      process_buffer(buffer)\n","#\n","#rocess_buffer(buffer)\n","#\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-14T01:47:24.328867Z","iopub.status.busy":"2023-09-14T01:47:24.328480Z","iopub.status.idle":"2023-09-14T01:47:35.074379Z","shell.execute_reply":"2023-09-14T01:47:35.073132Z","shell.execute_reply.started":"2023-09-14T01:47:24.328835Z"},"trusted":true},"outputs":[],"source":["train_data = pd.read_csv(f\"/kaggle/input/rsna-2023-abdominal-trauma-detection/train_series_meta.csv\")\n","cat_data = pd.read_csv(\"/kaggle/input/rsna-2023-abdominal-trauma-detection/train.csv\")\n","path = \"/kaggle/input/rsna-2023-abdominal-trauma-detection/train_images/\"\n","cleaned_df = get_data_for_3d_volumes(train_data, cat_data, path=path, number_idx=200)\n","print(\"Data extraction terminated...\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-14T01:47:35.080022Z","iopub.status.busy":"2023-09-14T01:47:35.077771Z","iopub.status.idle":"2023-09-14T01:47:35.123331Z","shell.execute_reply":"2023-09-14T01:47:35.121715Z","shell.execute_reply.started":"2023-09-14T01:47:35.079993Z"},"trusted":true},"outputs":[],"source":["cleaned_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-14T01:47:35.129577Z","iopub.status.busy":"2023-09-14T01:47:35.126054Z","iopub.status.idle":"2023-09-14T01:47:35.147176Z","shell.execute_reply":"2023-09-14T01:47:35.146184Z","shell.execute_reply.started":"2023-09-14T01:47:35.129544Z"},"trusted":true},"outputs":[],"source":["\n","df_injury = cleaned_df.loc[cleaned_df[\"Patient_category\"] == 1]\n","df_healthy = cleaned_df.loc[cleaned_df[\"Patient_category\"] == 0]\n","print(df_injury.count())\n","print(df_healthy.count())\n","df_injury = df_injury.iloc[0:20] \n","df_healthy = df_healthy.iloc[0:20]\n","\n","cleaned_df = pd.concat([df_injury, df_healthy])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-14T01:47:35.153761Z","iopub.status.busy":"2023-09-14T01:47:35.151494Z","iopub.status.idle":"2023-09-14T01:47:35.230967Z","shell.execute_reply":"2023-09-14T01:47:35.230170Z","shell.execute_reply.started":"2023-09-14T01:47:35.153728Z"},"trusted":true},"outputs":[],"source":["cleaned_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-14T01:47:35.237006Z","iopub.status.busy":"2023-09-14T01:47:35.234872Z","iopub.status.idle":"2023-09-14T01:47:35.314407Z","shell.execute_reply":"2023-09-14T01:47:35.313587Z","shell.execute_reply.started":"2023-09-14T01:47:35.236973Z"},"trusted":true},"outputs":[],"source":["cleaned_df = cleaned_df.reset_index(drop=True)\n","cleaned_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-14T01:47:35.320991Z","iopub.status.busy":"2023-09-14T01:47:35.318847Z","iopub.status.idle":"2023-09-14T01:52:33.683839Z","shell.execute_reply":"2023-09-14T01:52:33.682843Z","shell.execute_reply.started":"2023-09-14T01:47:35.320948Z"},"trusted":true},"outputs":[],"source":["volume_dcm = []\n","volume_labels = []\n","\n","for i in range(40):\n","    volume_img, depth = generate_patient_processed_data(cleaned_df[\"Patient_paths\"][i], cleaned_df[\"Patient_category\"][i])\n","    volume_dcm.append(volume_img)\n","    volume_labels.append(depth)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-14T01:52:33.685433Z","iopub.status.busy":"2023-09-14T01:52:33.685081Z","iopub.status.idle":"2023-09-14T01:52:34.334928Z","shell.execute_reply":"2023-09-14T01:52:34.333825Z","shell.execute_reply.started":"2023-09-14T01:52:33.685396Z"},"trusted":true},"outputs":[],"source":["volume_of_imgs = np.concatenate(volume_dcm, axis=2)\n","volume_of_labels = np.concatenate(volume_labels, axis=0)\n","volume_of_imgs.shape, volume_of_labels.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-14T01:52:34.339285Z","iopub.status.busy":"2023-09-14T01:52:34.338995Z","iopub.status.idle":"2023-09-14T01:52:34.343883Z","shell.execute_reply":"2023-09-14T01:52:34.342894Z","shell.execute_reply.started":"2023-09-14T01:52:34.339261Z"},"trusted":true},"outputs":[],"source":["transposed_volume_dcm = np.transpose(volume_of_imgs, (2, 0, 1))\n","transposed_volume_dcm = np.expand_dims(transposed_volume_dcm, axis=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-14T01:52:34.345905Z","iopub.status.busy":"2023-09-14T01:52:34.345286Z","iopub.status.idle":"2023-09-14T01:52:36.804418Z","shell.execute_reply":"2023-09-14T01:52:36.803402Z","shell.execute_reply.started":"2023-09-14T01:52:34.345841Z"},"trusted":true},"outputs":[],"source":["train_images , test_images , train_labels, test_labels = train_test_split(transposed_volume_dcm, volume_of_labels, test_size = 0.10, random_state = 0)"]},{"cell_type":"markdown","metadata":{},"source":["****Build Model Arquitecture****"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-14T01:52:36.806315Z","iopub.status.busy":"2023-09-14T01:52:36.805876Z","iopub.status.idle":"2023-09-14T01:52:36.818832Z","shell.execute_reply":"2023-09-14T01:52:36.817675Z","shell.execute_reply.started":"2023-09-14T01:52:36.806281Z"},"trusted":true},"outputs":[],"source":["def conv_block(input, num_filters):\n","\n","\tx = Conv2D(num_filters, 3, padding=\"same\")(input)\n","\tx = BatchNormalization()(x)\n","\tx = Activation(\"relu\")(x)\n","\n","\tx = Conv2D(num_filters, 3, padding=\"same\")(x)\n","\tx = BatchNormalization()(x)\n","\tx = Activation(\"relu\")(x)\n","\n","\treturn x \n","\n","def encoder_block(input, num_filters):\n","\n","\tx = conv_block(input, num_filters)\n","\tp = MaxPool2D((2, 2))(x)\n","\treturn x, p\n","\n","def dense_block(input_shape, num_classes):\n","\n","\tinputs = Input(shape=input_shape)\n","\t\n","\tx = Flatten()(inputs)\n","\tdense_layer_1 = Dense(units=512, activation='relu')(x)\n","\tdense_layer_1 = Dropout(0.4)(dense_layer_1)\n","\n","\t#dense_layer_2 = Dense(units=256, activation='relu')(dense_layer_1)\n","\t#dense_layer_2 = Dropout(0.4)(dense_layer_2)\n","\toutput_layer = Dense(units=num_classes, activation='softmax')(dense_layer_1)\n","\n","\treturn output_layer\n","\n","def build_unet_encoder_model_lstm(input_shape):\n","    units = 128\n","    inputs = Input(input_shape)\n","\n","\t#ENCODER\n","    s1, p1 = encoder_block(inputs, units/2)\n","    s2, p2 = encoder_block(p1, units)\n","    s3, p3 = encoder_block(p2, units*2)\n","    s4, p4 = encoder_block(p3, units*4)\n","    b1 = conv_block(p4, units*8)\n","    b2 = Flatten()(b1)\n","    encoder_output = b2 \n","    \n","    return Model(inputs, encoder_output)\n","\n","\n","def unet_encoder_lstm_model(input_shape, lstm_units):\n","    unet_encoder = build_unet_encoder_model_lstm(input_shape)\n","    # Convierte la salida del encoder en una secuencia 1D para la LSTM\n","    encoder_output = unet_encoder.output\n","    lstm_input = Reshape((-1, encoder_output.shape[1]))(encoder_output)\n","\n","    # capa LSTM\n","    lstm_layer = LSTM(lstm_units)(lstm_input)\n","\n","    # capa densa para la clasificaci√≥n \n","    output_layer = Dense(1, activation='sigmoid')(lstm_layer)\n","\n","    model = Model(inputs=unet_encoder.input, outputs=output_layer)\n","\n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["****RUN OF THE MODEL****"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-14T01:52:36.821090Z","iopub.status.busy":"2023-09-14T01:52:36.820040Z","iopub.status.idle":"2023-09-14T04:35:00.158472Z","shell.execute_reply":"2023-09-14T04:35:00.156707Z","shell.execute_reply.started":"2023-09-14T01:52:36.821064Z"},"trusted":true},"outputs":[],"source":["if __name__ == \"__main__\":\n","    \n","    \n","    input_shape = (128, 128, 1)\n","    num_classes = 2\n","    \n","    #Organize hyperparameters to track down\n","    config = SimpleNamespace(\n","        lstm_units = 100,\n","        L_R = 1e-5,\n","        LOSS = \"binary_crossentropy\",\n","        METRICS = \"accuracy\",\n","        EPOCHS = 200,\n","        BATCH_SIZE = 32 \n","    )\n","\n","    #Start the wandb run\n","    wandb.init(project=\"Unet-LSTM-2D-Model\", config=config)\n","        \n","    # Hyperparameters\n","    #lstm_units = 100\n","    #L_R = 1e-5\n","    #OPTIMIZER=tf.keras.optimizers.SGD(learning_rate=L_R)\n","    #LOSS = \"binary_crossentropy\"\n","    #METRICS = [\"accuracy\"]\n","    #EPOCHS = 200\n","    #BATCH_SIZE = 32\n","    OPTIMIZER=tf.keras.optimizers.SGD(learning_rate=config.L_R)\n","    \n","    #Model training\n","    \n","    model = unet_encoder_lstm_model(input_shape, config.lstm_units)\n","    model.compile(optimizer=OPTIMIZER, loss=config.LOSS, metrics=config.METRICS)\n","    model.summary()\n","    \n","    \n","    history = model.fit(train_images, train_labels, epochs=config.EPOCHS, batch_size=config.BATCH_SIZE, validation_data=(test_images, test_labels),\n","                        shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-14T05:22:20.049058Z","iopub.status.busy":"2023-09-14T05:22:20.048566Z","iopub.status.idle":"2023-09-14T05:23:19.524257Z","shell.execute_reply":"2023-09-14T05:23:19.523314Z","shell.execute_reply.started":"2023-09-14T05:22:20.049019Z"},"trusted":true},"outputs":[],"source":["#Log metrics over time to visualize performance\n","train_metrics = { \"accuracy\": model.metrics, \n","                 \"loss\": model.loss}\n","val_metrics = {\"val_accuracy\": history.history[\"val_accuracy\"],\n","                  \"val_loss\": history.history[\"val_loss\"]}\n","wandb.log(train_metrics)\n","wandb.log(val_metrics)\n","    \n","plt.plot(history.history[\"accuracy\"], label=\"Accuracy\")\n","plt.plot(history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Accuracy\")\n","plt.ylim([0.75, 1])\n","plt.legend(loc=\"lower right\")\n","\n","#Finish the run \n","\n","wandb.finish()"]}],"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
