{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import wandb\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Input, Flatten, LSTM, Dense, Reshape\nfrom tensorflow.keras.models import Model\n\nfrom types import SimpleNamespace\nimport keras\nimport numpy as np\nimport pandas as pd\nimport pydicom\nimport cv2\nfrom scipy.ndimage import zoom\nfrom sklearn import preprocessing\nfrom glob import glob\nimport re\nimport sqlite3\n\nimport matplotlib.pyplot as plt\nimport os \nimport nibabel as nib\nfrom glob import glob\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom keras import backend as K\ntf.config.run_functions_eagerly(True)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T01:46:20.683600Z","iopub.execute_input":"2023-09-14T01:46:20.683965Z","iopub.status.idle":"2023-09-14T01:46:30.227068Z","shell.execute_reply.started":"2023-09-14T01:46:20.683928Z","shell.execute_reply":"2023-09-14T01:46:30.226077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.login(anonymous=\"allow\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T01:46:30.229868Z","iopub.execute_input":"2023-09-14T01:46:30.231118Z","iopub.status.idle":"2023-09-14T01:47:24.260316Z","shell.execute_reply.started":"2023-09-14T01:46:30.231082Z","shell.execute_reply":"2023-09-14T01:47:24.259365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****DATA PREPROCESSING****","metadata":{}},{"cell_type":"code","source":"def window_converter(image, window_width=400, window_level=50):      \n    img_min = window_level - window_width // 2\n    img_max = window_level + window_width // 2\n    window_image = image.copy()\n    window_image[window_image < img_min] = img_min\n    window_image[window_image > img_max] = img_max\n    #image = (image / image.max() * 255).astype(np.float64)\n    return window_image\n\ndef transform_to_hu(medical_image, image):\n    meta_image = pydicom.dcmread(medical_image)\n    intercept = meta_image.RescaleIntercept\n    slope = meta_image.RescaleSlope\n    hu_image = image * slope + intercept\n    return hu_image\n\ndef standardize_pixel_array(dcm: pydicom.dataset.FileDataset) -> np.ndarray:\n    # Correct DICOM pixel_array if PixelRepresentation == 1.\n        pixel_array = dcm.pixel_array\n        if dcm.PixelRepresentation == 1:\n            bit_shift = dcm.BitsAllocated - dcm.BitsStored\n            dtype = pixel_array.dtype \n            pixel_array = (pixel_array << bit_shift).astype(dtype) >> bit_shift\n        return pixel_array\n    \ndef resize_img(img_paths, target_size=(128, 128)):\n        volume_shape = (target_size[0], target_size[1], len(img_paths)) \n        volume = np.zeros(volume_shape, dtype=np.float64)\n        for i, image_path in enumerate(img_paths):\n            image = pydicom.read_file(image_path)\n            image = standardize_pixel_array(image)\n            hu_image = transform_to_hu(image_path, image)\n            window_image = window_converter(hu_image)\n            image = cv2.resize(window_image, target_size)\n            volume[:,:,i] = image\n        return volume\n    \ndef normalize_volume(resized_volume):\n    original_shape = resized_volume.shape\n    flattened_image = resized_volume.reshape((-1,))\n    scaler = preprocessing.MinMaxScaler()\n    normalized_flattened_image = scaler.fit_transform(flattened_image.reshape((-1, 1)))\n    normalized_volume_image = normalized_flattened_image.reshape(original_shape)\n    return normalized_volume_image\n\ndef generate_patient_processed_data(list_img_paths, list_labels, target_size=(128,128)):\n\n    height = target_size[0]\n    width = target_size[1]\n    depth = len(list_img_paths)\n\n    volume_array = np.zeros((height, width, depth), dtype=np.float64)\n\n    print(\"Initializing data preprocessing with the following dimensions-> Volumes:{}\".format(volume_array.shape))\n\n    resized_images = resize_img(list_img_paths, target_size=target_size)\n    normalized_siz_volume = normalize_volume(resized_images)\n    volume_array = normalized_siz_volume\n    #volume_mask = create_3D_segmentations(list_seg_paths, target_size=target_size)\n    labels = [list_labels for i in range(depth)]\n    \n    return volume_array, labels#, volume_mask","metadata":{"execution":{"iopub.status.busy":"2023-09-14T01:47:24.262044Z","iopub.execute_input":"2023-09-14T01:47:24.262839Z","iopub.status.idle":"2023-09-14T01:47:24.279515Z","shell.execute_reply.started":"2023-09-14T01:47:24.262801Z","shell.execute_reply":"2023-09-14T01:47:24.278527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_number_from_path(path):\n    match = re.search(r'(\\d+)\\.dcm$', path)\n    if match:\n        return int(match.group(1))\n    return 0\n\n \n\ndef get_data_for_3d_volumes(data,train_data_cat, path, number_idx):\n\n    data_to_merge = data[[\"patient_id\", \"series_id\"]]\n    patient_category = train_data_cat[[\"patient_id\", \"any_injury\"]]\n\n    merged_df = data_to_merge.merge(patient_category, on='patient_id', how='left')\n\n    shuffled_data = merged_df.sample(frac=1, random_state=42)\n    shuffled_indexes = shuffled_data.index[:number_idx]\n    selected_rows = shuffled_data.loc[shuffled_indexes]\n    data_to_merge_processed = selected_rows.reset_index()\n\n    total_paths = []\n    patient_ids = []\n    series_ids = []\n    category = []\n\n    for patient_id in range(len(data_to_merge_processed)):\n\n        p_id = str(data_to_merge_processed[\"patient_id\"][patient_id]) + \"/\" + str(data_to_merge_processed[\"series_id\"][patient_id])\n        str_imgs_path = path + p_id + '/'\n        patient_img_paths = []\n\n \n\n        for file in glob(str_imgs_path + '/*'):\n            patient_img_paths.append(file)\n\n\n        sorted_file_paths = sorted(patient_img_paths, key=extract_number_from_path)\n        total_paths.append(sorted_file_paths)\n        patient_ids.append(data_to_merge_processed[\"patient_id\"][patient_id])\n        series_ids.append(data_to_merge_processed[\"series_id\"][patient_id])\n        category.append(data_to_merge_processed[\"any_injury\"][patient_id])\n\n    final_data = pd.DataFrame(list(zip(patient_ids, series_ids, total_paths, category)),\n               columns =[\"Patient_id\",\"Series_id\", \"Patient_paths\", \"Patient_category\"])\n\n    return final_data","metadata":{"execution":{"iopub.status.busy":"2023-09-14T01:47:24.282533Z","iopub.execute_input":"2023-09-14T01:47:24.282809Z","iopub.status.idle":"2023-09-14T01:47:24.295437Z","shell.execute_reply.started":"2023-09-14T01:47:24.282784Z","shell.execute_reply":"2023-09-14T01:47:24.294592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_number_from_path(path):\n    match = re.search(r'(\\d+)\\.dcm$', path)\n    if match:\n        return int(match.group(1))\n    return 0\ndef get_data_for_3d_volumes(data,train_data_cat, path, number_idx):\n    \n    data_to_merge = data[[\"patient_id\", \"series_id\"]]\n    patient_category = train_data_cat[[\"patient_id\", \"any_injury\"]]\n    \n    merged_df = data_to_merge.merge(patient_category, on='patient_id', how='left')\n    \n    shuffled_data = merged_df.sample(frac=1, random_state=42)\n    shuffled_indexes = shuffled_data.index[:number_idx]\n    selected_rows = shuffled_data.loc[shuffled_indexes]\n    data_to_merge_processed = selected_rows.reset_index()\n    \n    total_paths = []\n    patient_ids = []\n    series_ids = []\n    category = []\n    \n    for patient_id in range(len(data_to_merge_processed)):\n    \n        p_id = str(data_to_merge_processed[\"patient_id\"][patient_id]) + \"/\" + str(data_to_merge_processed[\"series_id\"][patient_id])\n        str_imgs_path = path + p_id + '/'\n        patient_img_paths = []\n\n        for file in glob(str_imgs_path + '/*'):\n            patient_img_paths.append(file)\n        \n        \n        sorted_file_paths = sorted(patient_img_paths, key=extract_number_from_path)\n        total_paths.append(sorted_file_paths)\n        patient_ids.append(data_to_merge_processed[\"patient_id\"][patient_id])\n        series_ids.append(data_to_merge_processed[\"series_id\"][patient_id])\n        category.append(data_to_merge_processed[\"any_injury\"][patient_id])\n    \n    final_data = pd.DataFrame(list(zip(patient_ids, series_ids, total_paths, category)),\n               columns =[\"Patient_id\",\"Series_id\", \"Patient_paths\", \"Patient_category\"])\n    \n    return final_data","metadata":{"execution":{"iopub.status.busy":"2023-09-14T01:47:24.299125Z","iopub.execute_input":"2023-09-14T01:47:24.299422Z","iopub.status.idle":"2023-09-14T01:47:24.312533Z","shell.execute_reply.started":"2023-09-14T01:47:24.299393Z","shell.execute_reply":"2023-09-14T01:47:24.311585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nbuffer_size = 10\nbuffer = []\n#\n#def process_buffer(buffer):\n #   if len(buffer) >= buffer_size:\n  #      X_batch = np.array(buffer)\n   #     y_batch = np.array([1])\n    #    lstm_model.train_on_batch(X_batch, y_batch)\n     #   buffer.clear()\n\n#for features_sequence in features_sequences:\n#    for feature_vector in features_sequence:\n #       buffer.append(feature_vector)\n  #      process_buffer(buffer)\n#\n#rocess_buffer(buffer)\n#\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T01:47:24.315715Z","iopub.execute_input":"2023-09-14T01:47:24.315970Z","iopub.status.idle":"2023-09-14T01:47:24.327054Z","shell.execute_reply.started":"2023-09-14T01:47:24.315946Z","shell.execute_reply":"2023-09-14T01:47:24.326106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(f\"/kaggle/input/rsna-2023-abdominal-trauma-detection/train_series_meta.csv\")\ncat_data = pd.read_csv(\"/kaggle/input/rsna-2023-abdominal-trauma-detection/train.csv\")\npath = \"/kaggle/input/rsna-2023-abdominal-trauma-detection/train_images/\"\ncleaned_df = get_data_for_3d_volumes(train_data, cat_data, path=path, number_idx=200)\nprint(\"Data extraction terminated...\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T01:47:24.328480Z","iopub.execute_input":"2023-09-14T01:47:24.328867Z","iopub.status.idle":"2023-09-14T01:47:35.074379Z","shell.execute_reply.started":"2023-09-14T01:47:24.328835Z","shell.execute_reply":"2023-09-14T01:47:35.073132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned_df","metadata":{"execution":{"iopub.status.busy":"2023-09-14T01:47:35.077771Z","iopub.execute_input":"2023-09-14T01:47:35.080022Z","iopub.status.idle":"2023-09-14T01:47:35.123331Z","shell.execute_reply.started":"2023-09-14T01:47:35.079993Z","shell.execute_reply":"2023-09-14T01:47:35.121715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf_injury = cleaned_df.loc[cleaned_df[\"Patient_category\"] == 1]\ndf_healthy = cleaned_df.loc[cleaned_df[\"Patient_category\"] == 0]\nprint(df_injury.count())\nprint(df_healthy.count())\ndf_injury = df_injury.iloc[0:20] \ndf_healthy = df_healthy.iloc[0:20]\n\ncleaned_df = pd.concat([df_injury, df_healthy])","metadata":{"execution":{"iopub.status.busy":"2023-09-14T01:47:35.126054Z","iopub.execute_input":"2023-09-14T01:47:35.129577Z","iopub.status.idle":"2023-09-14T01:47:35.147176Z","shell.execute_reply.started":"2023-09-14T01:47:35.129544Z","shell.execute_reply":"2023-09-14T01:47:35.146184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned_df","metadata":{"execution":{"iopub.status.busy":"2023-09-14T01:47:35.151494Z","iopub.execute_input":"2023-09-14T01:47:35.153761Z","iopub.status.idle":"2023-09-14T01:47:35.230967Z","shell.execute_reply.started":"2023-09-14T01:47:35.153728Z","shell.execute_reply":"2023-09-14T01:47:35.230170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned_df = cleaned_df.reset_index(drop=True)\ncleaned_df","metadata":{"execution":{"iopub.status.busy":"2023-09-14T01:47:35.234872Z","iopub.execute_input":"2023-09-14T01:47:35.237006Z","iopub.status.idle":"2023-09-14T01:47:35.314407Z","shell.execute_reply.started":"2023-09-14T01:47:35.236973Z","shell.execute_reply":"2023-09-14T01:47:35.313587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"volume_dcm = []\nvolume_labels = []\n\nfor i in range(40):\n    volume_img, depth = generate_patient_processed_data(cleaned_df[\"Patient_paths\"][i], cleaned_df[\"Patient_category\"][i])\n    volume_dcm.append(volume_img)\n    volume_labels.append(depth)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T01:47:35.318847Z","iopub.execute_input":"2023-09-14T01:47:35.320991Z","iopub.status.idle":"2023-09-14T01:52:33.683839Z","shell.execute_reply.started":"2023-09-14T01:47:35.320948Z","shell.execute_reply":"2023-09-14T01:52:33.682843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"volume_of_imgs = np.concatenate(volume_dcm, axis=2)\nvolume_of_labels = np.concatenate(volume_labels, axis=0)\nvolume_of_imgs.shape, volume_of_labels.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-14T01:52:33.685081Z","iopub.execute_input":"2023-09-14T01:52:33.685433Z","iopub.status.idle":"2023-09-14T01:52:34.334928Z","shell.execute_reply.started":"2023-09-14T01:52:33.685396Z","shell.execute_reply":"2023-09-14T01:52:34.333825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transposed_volume_dcm = np.transpose(volume_of_imgs, (2, 0, 1))\ntransposed_volume_dcm = np.expand_dims(transposed_volume_dcm, axis=3)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T01:52:34.338995Z","iopub.execute_input":"2023-09-14T01:52:34.339285Z","iopub.status.idle":"2023-09-14T01:52:34.343883Z","shell.execute_reply.started":"2023-09-14T01:52:34.339261Z","shell.execute_reply":"2023-09-14T01:52:34.342894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images , test_images , train_labels, test_labels = train_test_split(transposed_volume_dcm, volume_of_labels, test_size = 0.10, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T01:52:34.345286Z","iopub.execute_input":"2023-09-14T01:52:34.345905Z","iopub.status.idle":"2023-09-14T01:52:36.804418Z","shell.execute_reply.started":"2023-09-14T01:52:34.345841Z","shell.execute_reply":"2023-09-14T01:52:36.803402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Build Model Arquitecture****","metadata":{}},{"cell_type":"code","source":"def conv_block(input, num_filters):\n\n\tx = Conv2D(num_filters, 3, padding=\"same\")(input)\n\tx = BatchNormalization()(x)\n\tx = Activation(\"relu\")(x)\n\n\tx = Conv2D(num_filters, 3, padding=\"same\")(x)\n\tx = BatchNormalization()(x)\n\tx = Activation(\"relu\")(x)\n\n\treturn x \n\ndef encoder_block(input, num_filters):\n\n\tx = conv_block(input, num_filters)\n\tp = MaxPool2D((2, 2))(x)\n\treturn x, p\n\ndef dense_block(input_shape, num_classes):\n\n\tinputs = Input(shape=input_shape)\n\t\n\tx = Flatten()(inputs)\n\tdense_layer_1 = Dense(units=512, activation='relu')(x)\n\tdense_layer_1 = Dropout(0.4)(dense_layer_1)\n\n\t#dense_layer_2 = Dense(units=256, activation='relu')(dense_layer_1)\n\t#dense_layer_2 = Dropout(0.4)(dense_layer_2)\n\toutput_layer = Dense(units=num_classes, activation='softmax')(dense_layer_1)\n\n\treturn output_layer\n\ndef build_unet_encoder_model_lstm(input_shape):\n    units = 128\n    inputs = Input(input_shape)\n\n\t#ENCODER\n    s1, p1 = encoder_block(inputs, units/2)\n    s2, p2 = encoder_block(p1, units)\n    s3, p3 = encoder_block(p2, units*2)\n    s4, p4 = encoder_block(p3, units*4)\n    b1 = conv_block(p4, units*8)\n    b2 = Flatten()(b1)\n    encoder_output = b2 \n    \n    return Model(inputs, encoder_output)\n\n\ndef unet_encoder_lstm_model(input_shape, lstm_units):\n    unet_encoder = build_unet_encoder_model_lstm(input_shape)\n    # Convierte la salida del encoder en una secuencia 1D para la LSTM\n    encoder_output = unet_encoder.output\n    lstm_input = Reshape((-1, encoder_output.shape[1]))(encoder_output)\n\n    # capa LSTM\n    lstm_layer = LSTM(lstm_units)(lstm_input)\n\n    # capa densa para la clasificaci√≥n \n    output_layer = Dense(1, activation='sigmoid')(lstm_layer)\n\n    model = Model(inputs=unet_encoder.input, outputs=output_layer)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-09-14T01:52:36.805876Z","iopub.execute_input":"2023-09-14T01:52:36.806315Z","iopub.status.idle":"2023-09-14T01:52:36.818832Z","shell.execute_reply.started":"2023-09-14T01:52:36.806281Z","shell.execute_reply":"2023-09-14T01:52:36.817675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****RUN OF THE MODEL****","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    \n    \n    input_shape = (128, 128, 1)\n    num_classes = 2\n    \n    #Organize hyperparameters to track down\n    config = SimpleNamespace(\n        lstm_units = 100,\n        L_R = 1e-5,\n        LOSS = \"binary_crossentropy\",\n        METRICS = \"accuracy\",\n        EPOCHS = 200,\n        BATCH_SIZE = 32 \n    )\n\n    #Start the wandb run\n    wandb.init(project=\"Unet-LSTM-2D-Model\", config=config)\n        \n    # Hyperparameters\n    #lstm_units = 100\n    #L_R = 1e-5\n    #OPTIMIZER=tf.keras.optimizers.SGD(learning_rate=L_R)\n    #LOSS = \"binary_crossentropy\"\n    #METRICS = [\"accuracy\"]\n    #EPOCHS = 200\n    #BATCH_SIZE = 32\n    OPTIMIZER=tf.keras.optimizers.SGD(learning_rate=config.L_R)\n    \n    #Model training\n    \n    model = unet_encoder_lstm_model(input_shape, config.lstm_units)\n    model.compile(optimizer=OPTIMIZER, loss=config.LOSS, metrics=config.METRICS)\n    model.summary()\n    \n    \n    history = model.fit(train_images, train_labels, epochs=config.EPOCHS, batch_size=config.BATCH_SIZE, validation_data=(test_images, test_labels),\n                        shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T01:52:36.820040Z","iopub.execute_input":"2023-09-14T01:52:36.821090Z","iopub.status.idle":"2023-09-14T04:35:00.158472Z","shell.execute_reply.started":"2023-09-14T01:52:36.821064Z","shell.execute_reply":"2023-09-14T04:35:00.156707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Log metrics over time to visualize performance\ntrain_metrics = { \"accuracy\": model.metrics, \n                 \"loss\": model.loss}\nval_metrics = {\"val_accuracy\": history.history[\"val_accuracy\"],\n                  \"val_loss\": history.history[\"val_loss\"]}\nwandb.log(train_metrics)\nwandb.log(val_metrics)\n    \nplt.plot(history.history[\"accuracy\"], label=\"Accuracy\")\nplt.plot(history.history[\"val_accuracy\"], label=\"Validation accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.ylim([0.75, 1])\nplt.legend(loc=\"lower right\")\n\n#Finish the run \n\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T05:22:20.048566Z","iopub.execute_input":"2023-09-14T05:22:20.049058Z","iopub.status.idle":"2023-09-14T05:23:19.524257Z","shell.execute_reply.started":"2023-09-14T05:22:20.049019Z","shell.execute_reply":"2023-09-14T05:23:19.523314Z"},"trusted":true},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}