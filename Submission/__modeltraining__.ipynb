{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import tensorflow as tf\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Input, Flatten, LSTM, GRU, Dense, Reshape, TimeDistributed, Bidirectional, LeakyReLU\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from __datagen__ import DataGenerator\n",
    "from keras import Sequential\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from types import SimpleNamespace\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os \n",
    "from glob import glob\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# Get list of physical devices\n",
    "physical_devices = tf.config.experimental.list_physical_devices()\n",
    "# Check if GPU is availab\n",
    "gpu_devices = [device for device in physical_devices if device.device_type == 'GPU']\n",
    "\n",
    "# Print whether GPU is available\n",
    "if len(gpu_devices) > 0:\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjose-lunamr\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(anonymous=\"allow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUILD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input, num_filters):\n",
    "\n",
    "\tx = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "\tx = BatchNormalization()(x)\n",
    "\tx = Activation(\"relu\")(x)\n",
    "\tx = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "\tx = BatchNormalization()(x)\n",
    "\tx = Activation(\"relu\")(x)\n",
    "\treturn x \n",
    "\n",
    "def encoder_block(input, num_filters):\n",
    "\t\n",
    "\tx = conv_block(input, num_filters)\n",
    "\tp = MaxPool2D((2, 2))(x)\n",
    "\treturn x, p\n",
    "\n",
    "def dense_block(input_shape, num_classes):\n",
    "\n",
    "\tinputs = Input(shape=input_shape)\n",
    "\t\n",
    "\tx = Flatten()(inputs)\n",
    "\tdense_layer_1 = Dense(units=512, activation='relu')(x)\n",
    "\tdense_layer_1 = Dropout(0.4)(dense_layer_1)\n",
    "\n",
    "\t#dense_layer_2 = Dense(units=256, activation='relu')(dense_layer_1)\n",
    "\t#dense_layer_2 = Dropout(0.4)(dense_layer_2)\n",
    "\toutput_layer = Dense(units=num_classes, activation='softmax')(dense_layer_1)\n",
    "\n",
    "\treturn output_layer\n",
    "\n",
    "def build_unet_encoder_model_lstm(input_shape):\n",
    "    units = 128\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "\t#ENCODER\n",
    "    s1, p1 = encoder_block(inputs, units/2)\n",
    "    s2, p2 = encoder_block(p1, units)\n",
    "    s3, p3 = encoder_block(p2, units*2)\n",
    "    s4, p4 = encoder_block(p3, units*4)\n",
    "    b1 = conv_block(p4, units*8)\n",
    "    b2 = Flatten()(b1)\n",
    "    encoder_output = b2 \n",
    "    \n",
    "    return Model(inputs, encoder_output)\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def LSTM_model(input_shape, units_f1layer):\n",
    "\tinput_layer = Input(input_shape)\n",
    "\tlstm_layer1 = LSTM(units_f1layer, return_sequences=True)(input_layer)\n",
    "\tlstm_layer2 = LSTM(1024)(lstm_layer1)\n",
    "\tdense_layer1 = Dense(1024, activation=\"relu\")(lstm_layer2)\n",
    "\tdense_layer2 = Dense(1024, activation=\"relu\")(dense_layer1)\n",
    "\tlast_lstm_layer = dense_layer2\n",
    "\toutput_layer = Dense(13, activation=\"softmax\")(last_lstm_layer)\n",
    "\tmodel = Model(inputs=input_layer, outputs=output_layer)\n",
    "\treturn model\n",
    "\n",
    "def LSTM_model_v1(input_shape, units_f1layer):\n",
    "\tmodel = Sequential()\n",
    "\t\t\t\t\t\t\t\t\t# model.add(LSTM(512, return_sequences=True, input_shape=(64, 32768)))\n",
    "\tmodel.add(LSTM(8000, return_sequences=True, input_shape=(64, 32768)))\n",
    "\tmodel.add(LSTM(128, activation=\"relu\"))\n",
    "\tmodel.add(Dense(1024, activation=\"relu\"))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(512, activation=\"relu\"))\n",
    "\t\t\t\t\t\t\t\t\t# model.add(BatchNormalization())\n",
    "\tmodel.add(Dense(128, activation=\"relu\"))\n",
    "\tmodel.add(Dense(13, activation=\"softmax\"))\n",
    "\treturn model\n",
    "\n",
    "def LSTM_model_v2(input_shape, units_f1layer):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Bidirectional(LSTM(256, return_sequences=True), input_shape=input_shape))\n",
    "\tmodel.add(Bidirectional(LSTM(128, activation=\"relu\")))\n",
    "\tmodel.add(Dense(512, activation=\"relu\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=tf.keras.regularizers.L2(1e-4)))\n",
    "\tmodel.add(Dense(256, activation=\"relu\", kernel_initializer=\"glorot_uniform\"))  # Regularización L2\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Dense(13, activation=\"softmax\",kernel_regularizer=tf.keras.regularizers.L2(1e-4)))\n",
    "\treturn model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Daniel\\Desktop\\RSNA_Abdominal_Trauma\\Submission\\wandb\\run-20231107_141546-kyzaavny</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jose-lunamr/LSTM_normalized_Data_Bidirectional_ZeroDrop/runs/kyzaavny' target=\"_blank\">amber-vortex-5</a></strong> to <a href='https://wandb.ai/jose-lunamr/LSTM_normalized_Data_Bidirectional_ZeroDrop' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jose-lunamr/LSTM_normalized_Data_Bidirectional_ZeroDrop' target=\"_blank\">https://wandb.ai/jose-lunamr/LSTM_normalized_Data_Bidirectional_ZeroDrop</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jose-lunamr/LSTM_normalized_Data_Bidirectional_ZeroDrop/runs/kyzaavny' target=\"_blank\">https://wandb.ai/jose-lunamr/LSTM_normalized_Data_Bidirectional_ZeroDrop/runs/kyzaavny</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 64, 512)          1804288   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 256)              656384    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 13)                3341      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,727,949\n",
      "Trainable params: 2,727,437\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "#compilar LSTM 64 datapoints, 32 mil caracteristicas\n",
    "\n",
    "#Organize hyperparameters to track down\n",
    "config = SimpleNamespace(\n",
    "    input_shape = (64, 624),       # (64, 32768), Without 0s index drop\n",
    "    LSTM_layer1 = 256, #number of images per study\n",
    "    second_layer = 128,\n",
    "    L_R = 23e-4,\n",
    "    LOSS = \"binary_crossentropy\",\n",
    "    METRICS = [\"accuracy\", AUC()],\n",
    "    EPOCHS = 150,\n",
    "    BATCH_SIZE = 32, \n",
    ")\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Crear el Callback para reducir la tasa de aprendizaje en función de la pérdida en validación\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "\n",
    "#class_weights = compute_class_weight('balanced', classes=np.unique(train_generator.classes), y=train_generator.classes)\n",
    "\n",
    "CLASS_WEIGHTS = {\n",
    "    0:  0.5103795,\n",
    "    1: 24.5859375,\n",
    "    2: 0.53393281,\n",
    "    3: 7.8675,\n",
    "    4: 0.5306914,\n",
    "    5: 13.6826087,\n",
    "    6: 23.48507463,\n",
    "    7: 0.55679406,\n",
    "    8: 6.07528958,\n",
    "    9: 25.37903226,\n",
    "    10: 0.56337272,\n",
    "    11: 7.90703518,\n",
    "    12: 10.1516129\n",
    "}\n",
    "\n",
    "#Start the wandb run\n",
    "wandb.init(project=\"LSTM_normalized_Data_Bidirectional_ZeroDrop\", config=config)\n",
    "\n",
    "OPTIMIZER=tf.keras.optimizers.Adam(learning_rate=config.L_R)\n",
    "main_model = LSTM_model_v2(config.input_shape, config.LSTM_layer1)\n",
    "main_model.compile(optimizer=OPTIMIZER, loss=config.LOSS, metrics=config.METRICS)\n",
    "main_model.summary()\n",
    "tf.keras.utils.plot_model(main_model, to_file=\"/model.png\", show_shapes = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n",
      "c:\\Users\\Daniel\\miniconda3\\envs\\new_tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.5615 - accuracy: 0.0191 - auc: 0.8440\n",
      "Epoch 1: loss improved from inf to 0.56153, saving model to D:/Downloads/rsna-2023-abdominal-trauma-detection/Experiments_ckpt\\LSTM_V1.h5\n",
      "148/148 [==============================] - 215s 1s/step - loss: 0.5615 - accuracy: 0.0191 - auc: 0.8440 - lr: 0.0023\n",
      "Epoch 2/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4248 - accuracy: 0.0000e+00 - auc: 0.9240\n",
      "Epoch 2: loss improved from 0.56153 to 0.42477, saving model to D:/Downloads/rsna-2023-abdominal-trauma-detection/Experiments_ckpt\\LSTM_V1.h5\n",
      "148/148 [==============================] - 241s 2s/step - loss: 0.4248 - accuracy: 0.0000e+00 - auc: 0.9240 - lr: 0.0023\n",
      "Epoch 3/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4237 - accuracy: 0.0000e+00 - auc: 0.9234\n",
      "Epoch 3: loss improved from 0.42477 to 0.42368, saving model to D:/Downloads/rsna-2023-abdominal-trauma-detection/Experiments_ckpt\\LSTM_V1.h5\n",
      "148/148 [==============================] - 241s 2s/step - loss: 0.4237 - accuracy: 0.0000e+00 - auc: 0.9234 - lr: 0.0023\n",
      "Epoch 4/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4174 - accuracy: 0.0000e+00 - auc: 0.9239\n",
      "Epoch 4: loss improved from 0.42368 to 0.41735, saving model to D:/Downloads/rsna-2023-abdominal-trauma-detection/Experiments_ckpt\\LSTM_V1.h5\n",
      "148/148 [==============================] - 244s 2s/step - loss: 0.4174 - accuracy: 0.0000e+00 - auc: 0.9239 - lr: 0.0023\n",
      "Epoch 5/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4178 - accuracy: 0.0000e+00 - auc: 0.9240\n",
      "Epoch 5: loss did not improve from 0.41735\n",
      "148/148 [==============================] - 240s 2s/step - loss: 0.4178 - accuracy: 0.0000e+00 - auc: 0.9240 - lr: 0.0023\n",
      "Epoch 6/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4164 - accuracy: 0.0000e+00 - auc: 0.9232\n",
      "Epoch 6: loss improved from 0.41735 to 0.41638, saving model to D:/Downloads/rsna-2023-abdominal-trauma-detection/Experiments_ckpt\\LSTM_V1.h5\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4164 - accuracy: 0.0000e+00 - auc: 0.9232 - lr: 0.0023\n",
      "Epoch 7/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4174 - accuracy: 0.0000e+00 - auc: 0.9233\n",
      "Epoch 7: loss did not improve from 0.41638\n",
      "148/148 [==============================] - 240s 2s/step - loss: 0.4174 - accuracy: 0.0000e+00 - auc: 0.9233 - lr: 0.0023\n",
      "Epoch 8/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4159 - accuracy: 0.0000e+00 - auc: 0.9237\n",
      "Epoch 8: loss improved from 0.41638 to 0.41589, saving model to D:/Downloads/rsna-2023-abdominal-trauma-detection/Experiments_ckpt\\LSTM_V1.h5\n",
      "148/148 [==============================] - 245s 2s/step - loss: 0.4159 - accuracy: 0.0000e+00 - auc: 0.9237 - lr: 0.0023\n",
      "Epoch 9/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4133 - accuracy: 0.0000e+00 - auc: 0.9229\n",
      "Epoch 9: loss improved from 0.41589 to 0.41331, saving model to D:/Downloads/rsna-2023-abdominal-trauma-detection/Experiments_ckpt\\LSTM_V1.h5\n",
      "148/148 [==============================] - 251s 2s/step - loss: 0.4133 - accuracy: 0.0000e+00 - auc: 0.9229 - lr: 0.0023\n",
      "Epoch 10/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4149 - accuracy: 0.0000e+00 - auc: 0.9225\n",
      "Epoch 10: loss did not improve from 0.41331\n",
      "148/148 [==============================] - 245s 2s/step - loss: 0.4149 - accuracy: 0.0000e+00 - auc: 0.9225 - lr: 0.0023\n",
      "Epoch 11/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4131 - accuracy: 0.0000e+00 - auc: 0.9228\n",
      "Epoch 11: loss improved from 0.41331 to 0.41311, saving model to D:/Downloads/rsna-2023-abdominal-trauma-detection/Experiments_ckpt\\LSTM_V1.h5\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4131 - accuracy: 0.0000e+00 - auc: 0.9228 - lr: 0.0023\n",
      "Epoch 12/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4118 - accuracy: 0.0000e+00 - auc: 0.9231\n",
      "Epoch 12: loss improved from 0.41311 to 0.41183, saving model to D:/Downloads/rsna-2023-abdominal-trauma-detection/Experiments_ckpt\\LSTM_V1.h5\n",
      "148/148 [==============================] - 241s 2s/step - loss: 0.4118 - accuracy: 0.0000e+00 - auc: 0.9231 - lr: 0.0023\n",
      "Epoch 13/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4132 - accuracy: 0.0000e+00 - auc: 0.9230\n",
      "Epoch 13: loss did not improve from 0.41183\n",
      "148/148 [==============================] - 240s 2s/step - loss: 0.4132 - accuracy: 0.0000e+00 - auc: 0.9230 - lr: 0.0023\n",
      "Epoch 14/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4112 - accuracy: 0.0000e+00 - auc: 0.9229\n",
      "Epoch 14: loss improved from 0.41183 to 0.41122, saving model to D:/Downloads/rsna-2023-abdominal-trauma-detection/Experiments_ckpt\\LSTM_V1.h5\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4112 - accuracy: 0.0000e+00 - auc: 0.9229 - lr: 0.0023\n",
      "Epoch 15/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4119 - accuracy: 0.0000e+00 - auc: 0.9224\n",
      "Epoch 15: loss did not improve from 0.41122\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4119 - accuracy: 0.0000e+00 - auc: 0.9224 - lr: 0.0023\n",
      "Epoch 16/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4124 - accuracy: 0.0000e+00 - auc: 0.9231\n",
      "Epoch 16: loss did not improve from 0.41122\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4124 - accuracy: 0.0000e+00 - auc: 0.9231 - lr: 0.0023\n",
      "Epoch 17/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4117 - accuracy: 0.0000e+00 - auc: 0.9225\n",
      "Epoch 17: loss did not improve from 0.41122\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4117 - accuracy: 0.0000e+00 - auc: 0.9225 - lr: 0.0023\n",
      "Epoch 18/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4101 - accuracy: 0.0000e+00 - auc: 0.9223\n",
      "Epoch 18: loss improved from 0.41122 to 0.41013, saving model to D:/Downloads/rsna-2023-abdominal-trauma-detection/Experiments_ckpt\\LSTM_V1.h5\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4101 - accuracy: 0.0000e+00 - auc: 0.9223 - lr: 0.0023\n",
      "Epoch 19/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4128 - accuracy: 0.0000e+00 - auc: 0.9231\n",
      "Epoch 19: loss did not improve from 0.41013\n",
      "148/148 [==============================] - 244s 2s/step - loss: 0.4128 - accuracy: 0.0000e+00 - auc: 0.9231 - lr: 0.0023\n",
      "Epoch 20/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4094 - accuracy: 0.0000e+00 - auc: 0.9225\n",
      "Epoch 20: loss improved from 0.41013 to 0.40939, saving model to D:/Downloads/rsna-2023-abdominal-trauma-detection/Experiments_ckpt\\LSTM_V1.h5\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4094 - accuracy: 0.0000e+00 - auc: 0.9225 - lr: 0.0023\n",
      "Epoch 21/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4150 - accuracy: 4.2454e-04 - auc: 0.9227\n",
      "Epoch 21: loss did not improve from 0.40939\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4150 - accuracy: 4.2454e-04 - auc: 0.9227 - lr: 0.0023\n",
      "Epoch 22/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4113 - accuracy: 0.0000e+00 - auc: 0.9227\n",
      "Epoch 22: loss did not improve from 0.40939\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4113 - accuracy: 0.0000e+00 - auc: 0.9227 - lr: 0.0023\n",
      "Epoch 23/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4104 - accuracy: 0.0000e+00 - auc: 0.9231\n",
      "Epoch 23: loss did not improve from 0.40939\n",
      "148/148 [==============================] - 245s 2s/step - loss: 0.4104 - accuracy: 0.0000e+00 - auc: 0.9231 - lr: 0.0023\n",
      "Epoch 24/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4115 - accuracy: 0.0000e+00 - auc: 0.9226\n",
      "Epoch 24: loss did not improve from 0.40939\n",
      "148/148 [==============================] - 254s 2s/step - loss: 0.4115 - accuracy: 0.0000e+00 - auc: 0.9226 - lr: 0.0023\n",
      "Epoch 25/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4120 - accuracy: 0.0000e+00 - auc: 0.9227\n",
      "Epoch 25: loss did not improve from 0.40939\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4120 - accuracy: 0.0000e+00 - auc: 0.9227 - lr: 0.0023\n",
      "Epoch 26/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4074 - accuracy: 0.0000e+00 - auc: 0.9208\n",
      "Epoch 26: loss improved from 0.40939 to 0.40738, saving model to D:/Downloads/rsna-2023-abdominal-trauma-detection/Experiments_ckpt\\LSTM_V1.h5\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4074 - accuracy: 0.0000e+00 - auc: 0.9208 - lr: 0.0012\n",
      "Epoch 27/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4073 - accuracy: 0.0000e+00 - auc: 0.9219\n",
      "Epoch 27: loss improved from 0.40738 to 0.40726, saving model to D:/Downloads/rsna-2023-abdominal-trauma-detection/Experiments_ckpt\\LSTM_V1.h5\n",
      "148/148 [==============================] - 241s 2s/step - loss: 0.4073 - accuracy: 0.0000e+00 - auc: 0.9219 - lr: 0.0012\n",
      "Epoch 28/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4062 - accuracy: 0.0000e+00 - auc: 0.9219\n",
      "Epoch 28: loss improved from 0.40726 to 0.40616, saving model to D:/Downloads/rsna-2023-abdominal-trauma-detection/Experiments_ckpt\\LSTM_V1.h5\n",
      "148/148 [==============================] - 240s 2s/step - loss: 0.4062 - accuracy: 0.0000e+00 - auc: 0.9219 - lr: 0.0012\n",
      "Epoch 29/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4085 - accuracy: 0.0000e+00 - auc: 0.9221\n",
      "Epoch 29: loss did not improve from 0.40616\n",
      "148/148 [==============================] - 240s 2s/step - loss: 0.4085 - accuracy: 0.0000e+00 - auc: 0.9221 - lr: 0.0012\n",
      "Epoch 30/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4089 - accuracy: 0.0000e+00 - auc: 0.9215\n",
      "Epoch 30: loss did not improve from 0.40616\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4089 - accuracy: 0.0000e+00 - auc: 0.9215 - lr: 0.0012\n",
      "Epoch 31/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4091 - accuracy: 0.0000e+00 - auc: 0.9211\n",
      "Epoch 31: loss did not improve from 0.40616\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4091 - accuracy: 0.0000e+00 - auc: 0.9211 - lr: 0.0012\n",
      "Epoch 32/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4083 - accuracy: 0.0000e+00 - auc: 0.9214\n",
      "Epoch 32: loss did not improve from 0.40616\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4083 - accuracy: 0.0000e+00 - auc: 0.9214 - lr: 0.0012\n",
      "Epoch 33/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4076 - accuracy: 0.0000e+00 - auc: 0.9212\n",
      "Epoch 33: loss did not improve from 0.40616\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4076 - accuracy: 0.0000e+00 - auc: 0.9212 - lr: 0.0012\n",
      "Epoch 34/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4054 - accuracy: 0.0000e+00 - auc: 0.9201\n",
      "Epoch 34: loss improved from 0.40616 to 0.40544, saving model to D:/Downloads/rsna-2023-abdominal-trauma-detection/Experiments_ckpt\\LSTM_V1.h5\n",
      "148/148 [==============================] - 242s 2s/step - loss: 0.4054 - accuracy: 0.0000e+00 - auc: 0.9201 - lr: 5.7500e-04\n",
      "Epoch 35/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4059 - accuracy: 0.0000e+00 - auc: 0.9207\n",
      "Epoch 35: loss did not improve from 0.40544\n",
      "148/148 [==============================] - 240s 2s/step - loss: 0.4059 - accuracy: 0.0000e+00 - auc: 0.9207 - lr: 5.7500e-04\n",
      "Epoch 36/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4051 - accuracy: 0.0000e+00 - auc: 0.9206\n",
      "Epoch 36: loss improved from 0.40544 to 0.40506, saving model to D:/Downloads/rsna-2023-abdominal-trauma-detection/Experiments_ckpt\\LSTM_V1.h5\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4051 - accuracy: 0.0000e+00 - auc: 0.9206 - lr: 5.7500e-04\n",
      "Epoch 37/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4061 - accuracy: 0.0000e+00 - auc: 0.9210\n",
      "Epoch 37: loss did not improve from 0.40506\n",
      "148/148 [==============================] - 240s 2s/step - loss: 0.4061 - accuracy: 0.0000e+00 - auc: 0.9210 - lr: 5.7500e-04\n",
      "Epoch 38/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4063 - accuracy: 0.0000e+00 - auc: 0.9211\n",
      "Epoch 38: loss did not improve from 0.40506\n",
      "148/148 [==============================] - 245s 2s/step - loss: 0.4063 - accuracy: 0.0000e+00 - auc: 0.9211 - lr: 5.7500e-04\n",
      "Epoch 39/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4067 - accuracy: 0.0000e+00 - auc: 0.9213\n",
      "Epoch 39: loss did not improve from 0.40506\n",
      "148/148 [==============================] - 248s 2s/step - loss: 0.4067 - accuracy: 0.0000e+00 - auc: 0.9213 - lr: 5.7500e-04\n",
      "Epoch 40/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4052 - accuracy: 0.0000e+00 - auc: 0.9204\n",
      "Epoch 40: loss did not improve from 0.40506\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4052 - accuracy: 0.0000e+00 - auc: 0.9204 - lr: 5.7500e-04\n",
      "Epoch 41/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4072 - accuracy: 0.0000e+00 - auc: 0.9204\n",
      "Epoch 41: loss did not improve from 0.40506\n",
      "148/148 [==============================] - 245s 2s/step - loss: 0.4072 - accuracy: 0.0000e+00 - auc: 0.9204 - lr: 5.7500e-04\n",
      "Epoch 42/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4023 - accuracy: 0.0000e+00 - auc: 0.9193\n",
      "Epoch 42: loss improved from 0.40506 to 0.40228, saving model to D:/Downloads/rsna-2023-abdominal-trauma-detection/Experiments_ckpt\\LSTM_V1.h5\n",
      "148/148 [==============================] - 240s 2s/step - loss: 0.4023 - accuracy: 0.0000e+00 - auc: 0.9193 - lr: 2.8750e-04\n",
      "Epoch 43/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9207\n",
      "Epoch 43: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9207 - lr: 2.8750e-04\n",
      "Epoch 44/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4050 - accuracy: 0.0000e+00 - auc: 0.9199\n",
      "Epoch 44: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4050 - accuracy: 0.0000e+00 - auc: 0.9199 - lr: 2.8750e-04\n",
      "Epoch 45/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4054 - accuracy: 0.0000e+00 - auc: 0.9202\n",
      "Epoch 45: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4054 - accuracy: 0.0000e+00 - auc: 0.9202 - lr: 2.8750e-04\n",
      "Epoch 46/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4051 - accuracy: 0.0000e+00 - auc: 0.9204\n",
      "Epoch 46: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4051 - accuracy: 0.0000e+00 - auc: 0.9204 - lr: 2.8750e-04\n",
      "Epoch 47/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4054 - accuracy: 0.0000e+00 - auc: 0.9205\n",
      "Epoch 47: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4054 - accuracy: 0.0000e+00 - auc: 0.9205 - lr: 2.8750e-04\n",
      "Epoch 48/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.0000e+00 - auc: 0.9198\n",
      "Epoch 48: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4041 - accuracy: 0.0000e+00 - auc: 0.9198 - lr: 1.4375e-04\n",
      "Epoch 49/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4053 - accuracy: 0.0000e+00 - auc: 0.9198\n",
      "Epoch 49: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 242s 2s/step - loss: 0.4053 - accuracy: 0.0000e+00 - auc: 0.9198 - lr: 1.4375e-04\n",
      "Epoch 50/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.0000e+00 - auc: 0.9203\n",
      "Epoch 50: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4041 - accuracy: 0.0000e+00 - auc: 0.9203 - lr: 1.4375e-04\n",
      "Epoch 51/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4055 - accuracy: 0.0000e+00 - auc: 0.9205\n",
      "Epoch 51: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4055 - accuracy: 0.0000e+00 - auc: 0.9205 - lr: 1.4375e-04\n",
      "Epoch 52/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4039 - accuracy: 0.0000e+00 - auc: 0.9205\n",
      "Epoch 52: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4039 - accuracy: 0.0000e+00 - auc: 0.9205 - lr: 1.4375e-04\n",
      "Epoch 53/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4052 - accuracy: 0.0000e+00 - auc: 0.9202\n",
      "Epoch 53: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 245s 2s/step - loss: 0.4052 - accuracy: 0.0000e+00 - auc: 0.9202 - lr: 7.1875e-05\n",
      "Epoch 54/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4046 - accuracy: 0.0000e+00 - auc: 0.9204\n",
      "Epoch 54: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 246s 2s/step - loss: 0.4046 - accuracy: 0.0000e+00 - auc: 0.9204 - lr: 7.1875e-05\n",
      "Epoch 55/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4033 - accuracy: 0.0000e+00 - auc: 0.9199\n",
      "Epoch 55: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 245s 2s/step - loss: 0.4033 - accuracy: 0.0000e+00 - auc: 0.9199 - lr: 7.1875e-05\n",
      "Epoch 56/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4059 - accuracy: 0.0000e+00 - auc: 0.9203\n",
      "Epoch 56: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4059 - accuracy: 0.0000e+00 - auc: 0.9203 - lr: 7.1875e-05\n",
      "Epoch 57/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4053 - accuracy: 0.0000e+00 - auc: 0.9204\n",
      "Epoch 57: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 240s 2s/step - loss: 0.4053 - accuracy: 0.0000e+00 - auc: 0.9204 - lr: 7.1875e-05\n",
      "Epoch 58/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.0000e+00 - auc: 0.9195\n",
      "Epoch 58: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 324s 2s/step - loss: 0.4044 - accuracy: 0.0000e+00 - auc: 0.9195 - lr: 3.5938e-05\n",
      "Epoch 59/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4050 - accuracy: 0.0000e+00 - auc: 0.9204\n",
      "Epoch 59: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 257s 2s/step - loss: 0.4050 - accuracy: 0.0000e+00 - auc: 0.9204 - lr: 3.5938e-05\n",
      "Epoch 60/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4043 - accuracy: 0.0000e+00 - auc: 0.9204\n",
      "Epoch 60: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4043 - accuracy: 0.0000e+00 - auc: 0.9204 - lr: 3.5938e-05\n",
      "Epoch 61/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4039 - accuracy: 0.0000e+00 - auc: 0.9204\n",
      "Epoch 61: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4039 - accuracy: 0.0000e+00 - auc: 0.9204 - lr: 3.5938e-05\n",
      "Epoch 62/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4048 - accuracy: 0.0000e+00 - auc: 0.9202\n",
      "Epoch 62: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4048 - accuracy: 0.0000e+00 - auc: 0.9202 - lr: 3.5938e-05\n",
      "Epoch 63/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4052 - accuracy: 0.0000e+00 - auc: 0.9199\n",
      "Epoch 63: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4052 - accuracy: 0.0000e+00 - auc: 0.9199 - lr: 1.7969e-05\n",
      "Epoch 64/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.0000e+00 - auc: 0.9204\n",
      "Epoch 64: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 242s 2s/step - loss: 0.4044 - accuracy: 0.0000e+00 - auc: 0.9204 - lr: 1.7969e-05\n",
      "Epoch 65/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4056 - accuracy: 0.0000e+00 - auc: 0.9201\n",
      "Epoch 65: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4056 - accuracy: 0.0000e+00 - auc: 0.9201 - lr: 1.7969e-05\n",
      "Epoch 66/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4030 - accuracy: 0.0000e+00 - auc: 0.9207\n",
      "Epoch 66: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4030 - accuracy: 0.0000e+00 - auc: 0.9207 - lr: 1.7969e-05\n",
      "Epoch 67/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.0000e+00 - auc: 0.9205\n",
      "Epoch 67: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4049 - accuracy: 0.0000e+00 - auc: 0.9205 - lr: 1.7969e-05\n",
      "Epoch 68/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4045 - accuracy: 0.0000e+00 - auc: 0.9205\n",
      "Epoch 68: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 244s 2s/step - loss: 0.4045 - accuracy: 0.0000e+00 - auc: 0.9205 - lr: 8.9844e-06\n",
      "Epoch 69/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4051 - accuracy: 0.0000e+00 - auc: 0.9206\n",
      "Epoch 69: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 247s 2s/step - loss: 0.4051 - accuracy: 0.0000e+00 - auc: 0.9206 - lr: 8.9844e-06\n",
      "Epoch 70/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4050 - accuracy: 0.0000e+00 - auc: 0.9202\n",
      "Epoch 70: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 247s 2s/step - loss: 0.4050 - accuracy: 0.0000e+00 - auc: 0.9202 - lr: 8.9844e-06\n",
      "Epoch 71/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4053 - accuracy: 0.0000e+00 - auc: 0.9203\n",
      "Epoch 71: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4053 - accuracy: 0.0000e+00 - auc: 0.9203 - lr: 8.9844e-06\n",
      "Epoch 72/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4052 - accuracy: 0.0000e+00 - auc: 0.9203\n",
      "Epoch 72: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4052 - accuracy: 0.0000e+00 - auc: 0.9203 - lr: 8.9844e-06\n",
      "Epoch 73/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4043 - accuracy: 0.0000e+00 - auc: 0.9205\n",
      "Epoch 73: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4043 - accuracy: 0.0000e+00 - auc: 0.9205 - lr: 4.4922e-06\n",
      "Epoch 74/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4043 - accuracy: 0.0000e+00 - auc: 0.9199\n",
      "Epoch 74: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4043 - accuracy: 0.0000e+00 - auc: 0.9199 - lr: 4.4922e-06\n",
      "Epoch 75/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4060 - accuracy: 0.0000e+00 - auc: 0.9202\n",
      "Epoch 75: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4060 - accuracy: 0.0000e+00 - auc: 0.9202 - lr: 4.4922e-06\n",
      "Epoch 76/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.0000e+00 - auc: 0.9203\n",
      "Epoch 76: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4044 - accuracy: 0.0000e+00 - auc: 0.9203 - lr: 4.4922e-06\n",
      "Epoch 77/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4048 - accuracy: 0.0000e+00 - auc: 0.9202\n",
      "Epoch 77: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4048 - accuracy: 0.0000e+00 - auc: 0.9202 - lr: 4.4922e-06\n",
      "Epoch 78/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4054 - accuracy: 0.0000e+00 - auc: 0.9202\n",
      "Epoch 78: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4054 - accuracy: 0.0000e+00 - auc: 0.9202 - lr: 2.2461e-06\n",
      "Epoch 79/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.0000e+00 - auc: 0.9203\n",
      "Epoch 79: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 242s 2s/step - loss: 0.4044 - accuracy: 0.0000e+00 - auc: 0.9203 - lr: 2.2461e-06\n",
      "Epoch 80/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9199\n",
      "Epoch 80: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9199 - lr: 2.2461e-06\n",
      "Epoch 81/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4032 - accuracy: 0.0000e+00 - auc: 0.9205\n",
      "Epoch 81: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4032 - accuracy: 0.0000e+00 - auc: 0.9205 - lr: 2.2461e-06\n",
      "Epoch 82/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4051 - accuracy: 0.0000e+00 - auc: 0.9201\n",
      "Epoch 82: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4051 - accuracy: 0.0000e+00 - auc: 0.9201 - lr: 2.2461e-06\n",
      "Epoch 83/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4066 - accuracy: 0.0000e+00 - auc: 0.9199\n",
      "Epoch 83: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 244s 2s/step - loss: 0.4066 - accuracy: 0.0000e+00 - auc: 0.9199 - lr: 1.1230e-06\n",
      "Epoch 84/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4043 - accuracy: 0.0000e+00 - auc: 0.9205\n",
      "Epoch 84: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 248s 2s/step - loss: 0.4043 - accuracy: 0.0000e+00 - auc: 0.9205 - lr: 1.1230e-06\n",
      "Epoch 85/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4029 - accuracy: 0.0000e+00 - auc: 0.9205\n",
      "Epoch 85: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 332s 2s/step - loss: 0.4029 - accuracy: 0.0000e+00 - auc: 0.9205 - lr: 1.1230e-06\n",
      "Epoch 86/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4036 - accuracy: 0.0000e+00 - auc: 0.9202\n",
      "Epoch 86: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 257s 2s/step - loss: 0.4036 - accuracy: 0.0000e+00 - auc: 0.9202 - lr: 1.1230e-06\n",
      "Epoch 87/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.0000e+00 - auc: 0.9204\n",
      "Epoch 87: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4044 - accuracy: 0.0000e+00 - auc: 0.9204 - lr: 1.1230e-06\n",
      "Epoch 88/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4055 - accuracy: 0.0000e+00 - auc: 0.9203\n",
      "Epoch 88: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4055 - accuracy: 0.0000e+00 - auc: 0.9203 - lr: 1.0000e-06\n",
      "Epoch 89/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9204\n",
      "Epoch 89: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9204 - lr: 1.0000e-06\n",
      "Epoch 90/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.0000e+00 - auc: 0.9200\n",
      "Epoch 90: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4049 - accuracy: 0.0000e+00 - auc: 0.9200 - lr: 1.0000e-06\n",
      "Epoch 91/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4036 - accuracy: 0.0000e+00 - auc: 0.9202\n",
      "Epoch 91: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4036 - accuracy: 0.0000e+00 - auc: 0.9202 - lr: 1.0000e-06\n",
      "Epoch 92/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4039 - accuracy: 0.0000e+00 - auc: 0.9203\n",
      "Epoch 92: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4039 - accuracy: 0.0000e+00 - auc: 0.9203 - lr: 1.0000e-06\n",
      "Epoch 93/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4040 - accuracy: 0.0000e+00 - auc: 0.9204\n",
      "Epoch 93: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 243s 2s/step - loss: 0.4040 - accuracy: 0.0000e+00 - auc: 0.9204 - lr: 1.0000e-06\n",
      "Epoch 94/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9203\n",
      "Epoch 94: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9203 - lr: 1.0000e-06\n",
      "Epoch 95/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4054 - accuracy: 0.0000e+00 - auc: 0.9200\n",
      "Epoch 95: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4054 - accuracy: 0.0000e+00 - auc: 0.9200 - lr: 1.0000e-06\n",
      "Epoch 96/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4038 - accuracy: 0.0000e+00 - auc: 0.9202\n",
      "Epoch 96: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4038 - accuracy: 0.0000e+00 - auc: 0.9202 - lr: 1.0000e-06\n",
      "Epoch 97/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4039 - accuracy: 0.0000e+00 - auc: 0.9201\n",
      "Epoch 97: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4039 - accuracy: 0.0000e+00 - auc: 0.9201 - lr: 1.0000e-06\n",
      "Epoch 98/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4036 - accuracy: 0.0000e+00 - auc: 0.9200\n",
      "Epoch 98: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 244s 2s/step - loss: 0.4036 - accuracy: 0.0000e+00 - auc: 0.9200 - lr: 1.0000e-06\n",
      "Epoch 99/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4046 - accuracy: 0.0000e+00 - auc: 0.9200\n",
      "Epoch 99: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 247s 2s/step - loss: 0.4046 - accuracy: 0.0000e+00 - auc: 0.9200 - lr: 1.0000e-06\n",
      "Epoch 100/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4032 - accuracy: 0.0000e+00 - auc: 0.9205\n",
      "Epoch 100: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 244s 2s/step - loss: 0.4032 - accuracy: 0.0000e+00 - auc: 0.9205 - lr: 1.0000e-06\n",
      "Epoch 101/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4027 - accuracy: 0.0000e+00 - auc: 0.9201\n",
      "Epoch 101: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4027 - accuracy: 0.0000e+00 - auc: 0.9201 - lr: 1.0000e-06\n",
      "Epoch 102/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4048 - accuracy: 0.0000e+00 - auc: 0.9203\n",
      "Epoch 102: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4048 - accuracy: 0.0000e+00 - auc: 0.9203 - lr: 1.0000e-06\n",
      "Epoch 103/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4052 - accuracy: 0.0000e+00 - auc: 0.9204\n",
      "Epoch 103: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4052 - accuracy: 0.0000e+00 - auc: 0.9204 - lr: 1.0000e-06\n",
      "Epoch 104/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4040 - accuracy: 0.0000e+00 - auc: 0.9202\n",
      "Epoch 104: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4040 - accuracy: 0.0000e+00 - auc: 0.9202 - lr: 1.0000e-06\n",
      "Epoch 105/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4055 - accuracy: 0.0000e+00 - auc: 0.9199\n",
      "Epoch 105: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4055 - accuracy: 0.0000e+00 - auc: 0.9199 - lr: 1.0000e-06\n",
      "Epoch 106/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4052 - accuracy: 0.0000e+00 - auc: 0.9198\n",
      "Epoch 106: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4052 - accuracy: 0.0000e+00 - auc: 0.9198 - lr: 1.0000e-06\n",
      "Epoch 107/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4035 - accuracy: 0.0000e+00 - auc: 0.9201\n",
      "Epoch 107: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4035 - accuracy: 0.0000e+00 - auc: 0.9201 - lr: 1.0000e-06\n",
      "Epoch 108/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4024 - accuracy: 0.0000e+00 - auc: 0.9204\n",
      "Epoch 108: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4024 - accuracy: 0.0000e+00 - auc: 0.9204 - lr: 1.0000e-06\n",
      "Epoch 109/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9202\n",
      "Epoch 109: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 242s 2s/step - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9202 - lr: 1.0000e-06\n",
      "Epoch 110/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4029 - accuracy: 0.0000e+00 - auc: 0.9205\n",
      "Epoch 110: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4029 - accuracy: 0.0000e+00 - auc: 0.9205 - lr: 1.0000e-06\n",
      "Epoch 111/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4043 - accuracy: 0.0000e+00 - auc: 0.9204\n",
      "Epoch 111: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4043 - accuracy: 0.0000e+00 - auc: 0.9204 - lr: 1.0000e-06\n",
      "Epoch 112/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9201\n",
      "Epoch 112: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9201 - lr: 1.0000e-06\n",
      "Epoch 113/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.0000e+00 - auc: 0.9200\n",
      "Epoch 113: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 244s 2s/step - loss: 0.4041 - accuracy: 0.0000e+00 - auc: 0.9200 - lr: 1.0000e-06\n",
      "Epoch 114/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4039 - accuracy: 0.0000e+00 - auc: 0.9201\n",
      "Epoch 114: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 247s 2s/step - loss: 0.4039 - accuracy: 0.0000e+00 - auc: 0.9201 - lr: 1.0000e-06\n",
      "Epoch 115/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.0000e+00 - auc: 0.9200\n",
      "Epoch 115: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 245s 2s/step - loss: 0.4049 - accuracy: 0.0000e+00 - auc: 0.9200 - lr: 1.0000e-06\n",
      "Epoch 116/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4039 - accuracy: 0.0000e+00 - auc: 0.9205\n",
      "Epoch 116: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4039 - accuracy: 0.0000e+00 - auc: 0.9205 - lr: 1.0000e-06\n",
      "Epoch 117/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4048 - accuracy: 0.0000e+00 - auc: 0.9201\n",
      "Epoch 117: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 240s 2s/step - loss: 0.4048 - accuracy: 0.0000e+00 - auc: 0.9201 - lr: 1.0000e-06\n",
      "Epoch 118/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.0000e+00 - auc: 0.9201\n",
      "Epoch 118: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4044 - accuracy: 0.0000e+00 - auc: 0.9201 - lr: 1.0000e-06\n",
      "Epoch 119/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9206\n",
      "Epoch 119: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9206 - lr: 1.0000e-06\n",
      "Epoch 120/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.0000e+00 - auc: 0.9205\n",
      "Epoch 120: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4049 - accuracy: 0.0000e+00 - auc: 0.9205 - lr: 1.0000e-06\n",
      "Epoch 121/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4036 - accuracy: 0.0000e+00 - auc: 0.9203\n",
      "Epoch 121: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4036 - accuracy: 0.0000e+00 - auc: 0.9203 - lr: 1.0000e-06\n",
      "Epoch 122/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9199\n",
      "Epoch 122: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9199 - lr: 1.0000e-06\n",
      "Epoch 123/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.0000e+00 - auc: 0.9201\n",
      "Epoch 123: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4049 - accuracy: 0.0000e+00 - auc: 0.9201 - lr: 1.0000e-06\n",
      "Epoch 124/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4048 - accuracy: 0.0000e+00 - auc: 0.9204\n",
      "Epoch 124: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 242s 2s/step - loss: 0.4048 - accuracy: 0.0000e+00 - auc: 0.9204 - lr: 1.0000e-06\n",
      "Epoch 125/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4033 - accuracy: 0.0000e+00 - auc: 0.9207\n",
      "Epoch 125: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4033 - accuracy: 0.0000e+00 - auc: 0.9207 - lr: 1.0000e-06\n",
      "Epoch 126/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4038 - accuracy: 0.0000e+00 - auc: 0.9202\n",
      "Epoch 126: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4038 - accuracy: 0.0000e+00 - auc: 0.9202 - lr: 1.0000e-06\n",
      "Epoch 127/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4043 - accuracy: 0.0000e+00 - auc: 0.9205\n",
      "Epoch 127: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4043 - accuracy: 0.0000e+00 - auc: 0.9205 - lr: 1.0000e-06\n",
      "Epoch 128/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4046 - accuracy: 0.0000e+00 - auc: 0.9201\n",
      "Epoch 128: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 244s 2s/step - loss: 0.4046 - accuracy: 0.0000e+00 - auc: 0.9201 - lr: 1.0000e-06\n",
      "Epoch 129/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4051 - accuracy: 0.0000e+00 - auc: 0.9199\n",
      "Epoch 129: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 247s 2s/step - loss: 0.4051 - accuracy: 0.0000e+00 - auc: 0.9199 - lr: 1.0000e-06\n",
      "Epoch 130/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4033 - accuracy: 0.0000e+00 - auc: 0.9207\n",
      "Epoch 130: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 245s 2s/step - loss: 0.4033 - accuracy: 0.0000e+00 - auc: 0.9207 - lr: 1.0000e-06\n",
      "Epoch 131/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4039 - accuracy: 0.0000e+00 - auc: 0.9203\n",
      "Epoch 131: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4039 - accuracy: 0.0000e+00 - auc: 0.9203 - lr: 1.0000e-06\n",
      "Epoch 132/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4048 - accuracy: 0.0000e+00 - auc: 0.9203\n",
      "Epoch 132: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4048 - accuracy: 0.0000e+00 - auc: 0.9203 - lr: 1.0000e-06\n",
      "Epoch 133/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9204\n",
      "Epoch 133: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9204 - lr: 1.0000e-06\n",
      "Epoch 134/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4034 - accuracy: 0.0000e+00 - auc: 0.9200\n",
      "Epoch 134: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4034 - accuracy: 0.0000e+00 - auc: 0.9200 - lr: 1.0000e-06\n",
      "Epoch 135/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4039 - accuracy: 0.0000e+00 - auc: 0.9203\n",
      "Epoch 135: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4039 - accuracy: 0.0000e+00 - auc: 0.9203 - lr: 1.0000e-06\n",
      "Epoch 136/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.0000e+00 - auc: 0.9204\n",
      "Epoch 136: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4044 - accuracy: 0.0000e+00 - auc: 0.9204 - lr: 1.0000e-06\n",
      "Epoch 137/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9203\n",
      "Epoch 137: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9203 - lr: 1.0000e-06\n",
      "Epoch 138/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4054 - accuracy: 0.0000e+00 - auc: 0.9207\n",
      "Epoch 138: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4054 - accuracy: 0.0000e+00 - auc: 0.9207 - lr: 1.0000e-06\n",
      "Epoch 139/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4052 - accuracy: 0.0000e+00 - auc: 0.9199\n",
      "Epoch 139: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 242s 2s/step - loss: 0.4052 - accuracy: 0.0000e+00 - auc: 0.9199 - lr: 1.0000e-06\n",
      "Epoch 140/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4053 - accuracy: 0.0000e+00 - auc: 0.9199\n",
      "Epoch 140: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4053 - accuracy: 0.0000e+00 - auc: 0.9199 - lr: 1.0000e-06\n",
      "Epoch 141/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4042 - accuracy: 0.0000e+00 - auc: 0.9202\n",
      "Epoch 141: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4042 - accuracy: 0.0000e+00 - auc: 0.9202 - lr: 1.0000e-06\n",
      "Epoch 142/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.0000e+00 - auc: 0.9202\n",
      "Epoch 142: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4049 - accuracy: 0.0000e+00 - auc: 0.9202 - lr: 1.0000e-06\n",
      "Epoch 143/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4053 - accuracy: 0.0000e+00 - auc: 0.9202\n",
      "Epoch 143: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 245s 2s/step - loss: 0.4053 - accuracy: 0.0000e+00 - auc: 0.9202 - lr: 1.0000e-06\n",
      "Epoch 144/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9203\n",
      "Epoch 144: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 253s 2s/step - loss: 0.4047 - accuracy: 0.0000e+00 - auc: 0.9203 - lr: 1.0000e-06\n",
      "Epoch 145/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4034 - accuracy: 0.0000e+00 - auc: 0.9208\n",
      "Epoch 145: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4034 - accuracy: 0.0000e+00 - auc: 0.9208 - lr: 1.0000e-06\n",
      "Epoch 146/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4053 - accuracy: 0.0000e+00 - auc: 0.9203\n",
      "Epoch 146: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4053 - accuracy: 0.0000e+00 - auc: 0.9203 - lr: 1.0000e-06\n",
      "Epoch 147/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4040 - accuracy: 0.0000e+00 - auc: 0.9202\n",
      "Epoch 147: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 239s 2s/step - loss: 0.4040 - accuracy: 0.0000e+00 - auc: 0.9202 - lr: 1.0000e-06\n",
      "Epoch 148/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4023 - accuracy: 0.0000e+00 - auc: 0.9201\n",
      "Epoch 148: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4023 - accuracy: 0.0000e+00 - auc: 0.9201 - lr: 1.0000e-06\n",
      "Epoch 149/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4046 - accuracy: 0.0000e+00 - auc: 0.9203\n",
      "Epoch 149: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4046 - accuracy: 0.0000e+00 - auc: 0.9203 - lr: 1.0000e-06\n",
      "Epoch 150/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 0.4039 - accuracy: 0.0000e+00 - auc: 0.9205\n",
      "Epoch 150: loss did not improve from 0.40228\n",
      "148/148 [==============================] - 238s 2s/step - loss: 0.4039 - accuracy: 0.0000e+00 - auc: 0.9205 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    checkpoint_filepath = 'D:/Downloads/rsna-2023-abdominal-trauma-detection/Experiments_ckpt/LSTM_V1.h5'\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                              monitor=\"loss\",\n",
    "                                                              save_best_only=True,\n",
    "                                                              save_weights_only=False,\n",
    "                                                              mode=\"min\",\n",
    "                                                              verbose=1)\n",
    "    callbacks = [model_checkpoint_callback]\n",
    "    data = pd.read_csv(\"C:/Users/Daniel/Desktop/RSNA_Abdominal_Trauma/local_database/train_data_lstm.csv\")\n",
    "    datagen = DataGenerator(data['Patient_id'], data['Series_id'], config.BATCH_SIZE)\n",
    "    history = main_model.fit(datagen, epochs=config.EPOCHS, shuffle=False, callbacks=[callbacks, lr_scheduler,WandbCallback()], class_weight = CLASS_WEIGHTS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
